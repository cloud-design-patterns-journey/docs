{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Internal Docs","text":"<p>Static documentation site for Cloud Deisgn Patterns learning journey.</p> <p>Contribute.</p>"},{"location":"labs/genai/genai-ops-kubectl-ai/","title":"Streamline kubernetes operations with <code>kubectl-ai</code>","text":""},{"location":"labs/genai/genai-ops-kubectl-ai/#lab-outline","title":"Lab Outline","text":"<ul> <li>Duration: 30 minutes</li> <li>Objective: Enable engineering students to quickly install, configure, and use <code>kubectl-ai</code> to manage Kubernetes clusters using natural language queries.</li> </ul>"},{"location":"labs/genai/genai-ops-kubectl-ai/#content","title":"Content","text":"<ul> <li>Streamline kubernetes operations with <code>kubectl-ai</code></li> <li>Lab Outline</li> <li>Content</li> <li>Prerequisites</li> <li>Introduction to <code>kubectl-ai</code></li> <li>Lab Instructions<ul> <li>Installing <code>kubectl-ai</code> (Linux and MacOS)</li> <li>Running <code>kubectl-ai</code> with OpenAI compatible provider</li> <li>Running individual queries</li> <li>Generating YAML manifests</li> <li>Explore additional examples</li> </ul> </li> <li>Conclusion</li> </ul>"},{"location":"labs/genai/genai-ops-kubectl-ai/#prerequisites","title":"Prerequisites","text":"<ul> <li>OpenAI compatible LLM server exposing models (<code>Mistral Large</code> as example in this lab).<ul> <li>If running this lab as part of a workshop, one is given to you e.g. <code>http://models.apps.devopsp.mop.demo</code>.</li> </ul> </li> <li>Access to a terminal with <code>kubectl</code> installed and configured to a K8s cluster.</li> <li>We recommend minikube or kind.</li> </ul>"},{"location":"labs/genai/genai-ops-kubectl-ai/#introduction-to-kubectl-ai","title":"Introduction to <code>kubectl-ai</code>","text":"<ul> <li><code>kubectl-ai</code> is an AI-powered Kubernetes assistant that allows you to manage clusters using plain English, translating your requests into valid <code>kubectl</code> commands or YAML manifests.</li> <li>It supports multiple AI models (Google Gemini by default, OpenAI, Azure OpenAI, local LLMs like Ollama).</li> <li>Key benefits: reduces Kubernetes learning curve, boosts productivity, and democratizes cluster access.</li> </ul>"},{"location":"labs/genai/genai-ops-kubectl-ai/#lab-instructions","title":"Lab Instructions","text":""},{"location":"labs/genai/genai-ops-kubectl-ai/#installing-kubectl-ai-linux-and-macos","title":"Installing <code>kubectl-ai</code> (Linux and MacOS)","text":"<ol> <li>Install the <code>kubectl-ai</code> plugin:     <pre><code>curl -sSL https://raw.githubusercontent.com/GoogleCloudPlatform/kubectl-ai/main/install.sh | bash\n</code></pre></li> <li>Verify installation:     <pre><code>kubectl ai --help\n</code></pre></li> </ol>"},{"location":"labs/genai/genai-ops-kubectl-ai/#running-kubectl-ai-with-openai-compatible-provider","title":"Running <code>kubectl-ai</code> with OpenAI compatible provider","text":"<pre><code>export OPENAI_API_KEY=sk-CHANGEME\nexport OPENAI_ENDPOINT=http://CHANGEME/v1\nkubectl ai --llm-provider=openai --model=mistral-large\n</code></pre> <p>Note</p> <p>If running this lab in a workshop setup, you should have a LiteLLM proxy OpenAI compatible server running, you can find the route (endpoint) and API key in the <code>ai-models</code> namespace. The API key is the <code>LITELLM_MASTER_KEY</code> value of the <code>litellm-secret</code> secret.</p> <p>This has started an interactive session, you can start asking questions with follow-up:</p> <p><pre><code>Create an nginx deployment with 1 replicas in the genai-CHANGEME namespace\n</code></pre> <pre><code>Get the logs\n</code></pre></p>"},{"location":"labs/genai/genai-ops-kubectl-ai/#running-individual-queries","title":"Running individual queries","text":"<p>Try the following commands and observe the AI-generated <code>kubectl</code> commands. Adapt as required by your context:</p> <p><pre><code>kubectl ai \"Create an nginx deployment with 1 replicas in the genai-CHANGEME namespace for OpenShift\" --llm-provider=openai --model=mistral-large \n</code></pre> <pre><code>kubectl ai \"Scale my nginx deployment to 2 replicas\" --llm-provider=openai --model=mistral-large \n</code></pre> <pre><code>kubectl ai \"Show me all pods that failed in the last hour\" --llm-provider=openai --model=mistral-large \n</code></pre> <pre><code>kubectl ai \"Generate a HorizontalPodAutoscaler YAML for the web-api deployment\" --llm-provider=openai --model=mistral-large \n</code></pre> <pre><code>kubectl ai \"Show me the logs for the nginx pod in the genai-CHANGEME namespace\" --llm-provider=openai --model=mistral-large \n</code></pre></p>"},{"location":"labs/genai/genai-ops-kubectl-ai/#generating-yaml-manifests","title":"Generating YAML manifests","text":"<pre><code>kubectl ai \"Write a deployment with nginx and a service that exposes port 80\" --llm-provider=openai --model=mistral-large \n</code></pre> <p>The tool will generate YAML and ask if you want to apply it.</p>"},{"location":"labs/genai/genai-ops-kubectl-ai/#explore-additional-examples","title":"Explore additional examples","text":"<p>Explore these extra scenarios to deepen your hands-on experience with <code>kubectl-ai</code>. These examples cover both common and advanced Kubernetes operations, all using natural language.</p> <p>Create and Update Resources</p> <p><pre><code>Create an nginx deployment with 1 replicas\n</code></pre> <pre><code>Update the nginx deployment to use 2 replicas and expose port 8080\n</code></pre> <pre><code>Create a genai-CHANGEME namespace, then create an nginx pod in that namespace\n</code></pre></p> <p>Service and Networking</p> <p><pre><code>Create a service of type LoadBalancer for my nginx deployment\n</code></pre> <pre><code>Expose the redis deployment on port 6379 as a ClusterIP service\n</code></pre> <pre><code>Set up a NetworkPolicy to only allow traffic to the frontend deployment from the genai-CHANGEME namespace\n</code></pre></p> <p>Pod and Deployment Management</p> <p><pre><code>Restart all pods in the genai-CHANGEME namespace\n</code></pre> <pre><code>Delete the pod named my-app-123 in the genai-CHANGEME namespace\n</code></pre> <pre><code>Show the status of all deployments in the kube-system namespace\n</code></pre></p> <p>Logs and Troubleshooting</p> <p><pre><code>Fetch logs for the nginx app in the genai-CHANGEME namespace\n</code></pre> <pre><code>Show events for the backend deployment\n</code></pre> <pre><code>Explain the error in this log \n</code></pre></p> <p>Note</p> <p>(pipe a log file: <code>cat error.log | kubectl-ai \"explain the error</code> --llm-provider=openai --model=mistral-large )</p> <p>Scaling and Autoscaling</p> <p><pre><code>Scale the production app to 2 replicas\n</code></pre> <pre><code>Generate a HorizontalPodAutoscaler YAML for the api-server deployment\n</code></pre></p> <p>Advanced YAML Generation</p> <p><pre><code>Write a deployment YAML for a Python app using the image python:3.9 with environment variable DEBUG=true\n</code></pre> <pre><code>Create a ConfigMap named app-config with keys LOG_LEVEL=debug and TIMEOUT=30\n</code></pre> <pre><code>Generate a Secret manifest with username=admin and password=Pa\\$\\$w0rd\n</code></pre></p> <p>Batch and Multiple Resources</p> <p><pre><code>Create a namespace called genai-CHANGEME, then deploy a busybox pod in it\n</code></pre> <pre><code>Create a deployment and a service for a MongoDB database in the genai-CHANGEME namespace\n</code></pre></p>"},{"location":"labs/genai/genai-ops-kubectl-ai/#conclusion","title":"Conclusion","text":"<p>By the end of this lab, you should be able to: - Install and configure <code>kubectl-ai</code> - Use natural language to manage Kubernetes resources - Generate and apply YAML manifests using AI</p> <p>Feel free to experiment with your own queries and switch to other provided LLMs, then reflect on the productivity gains from using AI-powered Kubernetes tooling, make sure to also challenge the risks of such tools in the context of Agentic AI.</p>"},{"location":"labs/inventory-app/fast-track/","title":"Fast Track","text":"<p>Develop an example application with a three-tier microservices architecture and deploy it into Red Hat OpenShift on premises, on AWS, Azure or IBM Cloud. This OpenShift development environment has been pre-configured with a sample SDLC (Software Delivery Life Cycle).</p>"},{"location":"labs/inventory-app/fast-track/#business-need","title":"Business Need","text":"<p>In this guide, imagine you have completed an Enterprise Design Thinking Workshop and the result is an MVP statement that defines the desired business outcomes. Use the steps below to help deliver this MVP quickly while following Garage Method best practices.</p>"},{"location":"labs/inventory-app/fast-track/#mvp-statement","title":"MVP Statement","text":"<p>An MVP is a first hill. Here's the hill statement for the MVP we're going to build:</p> <ul> <li> <p>Who: Distribution employees in each of the regional warehouses</p> </li> <li> <p>What: A secure web application that enables easy access to list of product SKU inventory levels and inventory locations</p> </li> <li> <p>Wow: Make the system appealing and easy to use. Develop it quickly as a minimum viable product. Use the latest managed container runtimes and DevOps best practices to enable post MVP feature improvements. Simulate a release to a Test environment.</p> </li> </ul>"},{"location":"labs/inventory-app/fast-track/#architecture","title":"Architecture","text":"<p>We will build an application that is made up of microservices in three-tier architecture. Each tier encapsulates a clean separation of concerns. Each app microservice component will be modelled using microservices and use a number of polyglot programming languages and frameworks. Data will be stored in a NoSQL Database.</p> <p></p>"},{"location":"labs/inventory-app/fast-track/#user-interface","title":"User interface","text":"<p>The user experience for the application has been designed by the design team and this drives the requirements for the development team.</p>"},{"location":"labs/inventory-app/fast-track/#technical-requirements","title":"Technical Requirements","text":"<p>The Micro services should adhere to the following technical requirements:</p> <ul> <li>Microservices<ul> <li>Stateless</li> <li>REST APIs</li> <li>Polyglot</li> </ul> </li> <li>DevOps with CI/CD (continuous integration and continuous delivery) <ul> <li>Use in cluster CI technology to be efficient and secure</li> <li>Use latest GitOps best practices</li> <li>Monitoring and logging</li> <li>Code analysis</li> <li>App security</li> </ul> </li> <li>Deployed to Red Hat OpenShift cluster which is based on Kubernetes open source technology</li> <li>Follow the Carbon Design System user experience</li> </ul>"},{"location":"labs/inventory-app/fast-track/#fast-track-guide","title":"Fast Track Guide","text":""},{"location":"labs/inventory-app/fast-track/#deploy-inventory-service","title":"Deploy inventory service","text":"<ul> <li> <p>Create a new repository for the service from the Inventory Service Solution template. Make the cloned repository public.</p> <p>Warning</p> <p>In order to prevent naming collisions if you are running this as part of a workshop, chose the GitHub organization you have been invited to as <code>Owner</code> and name the repository <code>inv-svc-${UNIQUE_SUFFIX}</code>, replacing <code>${UNIQUE_SUFFIX}</code> with your team name or initials.</p> </li> <li> <p>Deploy this application with Tekton:</p> <p>Note</p> <p>You should have the <code>tkn</code>, <code>tkn pac</code> and <code>oc</code> CLIs installed. <code>oc</code> can be installed through the help section of your OpenShift console.</p> </li> <li> <p>In the OpenShift web console, click on the user ID on the top right, click on Copy login command and get the OpenShift login command, which includes a token.</p> <p></p> </li> <li> <p>Click on Display Token, copy the Login with the token. oc login command will log you in. Run the login command in your terminal:</p> <pre><code>oc login --token=&lt;OCP_TOKEN&gt; --server=&lt;OCP_SERVER&gt;\n</code></pre> </li> <li> <p>Create a new <code>inventory-${UNIQUE_SUFFIX}-dev</code> project (setting the <code>UNIQUE_SUFFIX</code> environment variables with your team name or initials to have a unique name):</p> <pre><code>export UNIQUE_SUFFIX=ns # CHANGEME\noc new-project inventory-${UNIQUE_SUFFIX}-dev\n</code></pre> </li> <li> <p>Create <code>registry-config</code> and <code>ci-config</code> secrets required for your pipeline runs to access your container registry:</p> <pre><code>cat &lt;&lt;EOF | oc apply -f -\n---\nkind: Secret\napiVersion: v1\nmetadata:\n  name: registry-config\n  namespace: inventory-${UNIQUE_SUFFIX}-dev\nstringData:\n  config.json: '{\"auths\":...}' # CHANGEME\ntype: Opaque\n---\nkind: Secret\napiVersion: v1\nmetadata:\n  name: ci-config\n  namespace: inventory-${UNIQUE_SUFFIX}-dev\nstringData:\n  img-namespace: library # CHANGEME\n  img-server: core.harbor.example.com # CHANGEME\ntype: Opaque\nEOF\n</code></pre> </li> </ul> <p>!!! note       If you are doing this lab as part of a workshop secrets have been created for you in the <code>ci-tools</code> namespace, you just need to copy them:</p> <pre><code>    ```sh\n    oc get secret registry-config -n ci-tools -o yaml | sed \"s/ci-tools/inventory-${UNIQUE_SUFFIX}-dev/g\" | oc apply -f -\n    oc get secret ci-config -n ci-tools -o yaml | sed \"s/ci-tools/inventory-${UNIQUE_SUFFIX}-dev/g\" | oc apply -f -\n    ```\n</code></pre> <ul> <li> <p>Clone the repo locally:</p> <pre><code>git clone https://github.com/cloud-design-patterns-journey/inv-svc-${UNIQUE_SUFFIX}.git\ncd inv-svc-${UNIQUE_SUFFIX}\n</code></pre> </li> <li> <p>Create the tekton pipeline for the backend service your new project:</p> <pre><code>oc adm policy add-scc-to-user privileged -z pipeline\ntkn pac create repository\n</code></pre> </li> </ul> <p>!!! note       - <code>tkn pac create repository</code> assumes you have Pipelines-as-Code already setup on your cluster and Git provider. If you are running this lab as part of a workshop, this has been configured for you, make sure you use the provided GitHub organization when you create yout Git repository from template above.       - <code>oc adm policy add-scc-to-user privileged -z pipeline</code> will make sure that the Tekton pipeline will be able to escalade privileges in your <code>inventory-${UNIQUE_SUFFIX}-dev</code> project/namespace.</p> <ul> <li> <p>In OpenShift console (Pipelines Section &gt; Pipelines &gt; Repositories), edit the newly created <code>Repository</code> YAML to add cluster specific configuration (e.g. image repository):</p> <pre><code>...\nspec:\n  params:\n  - name: img-server\n    secret_ref:\n      name: ci-config\n      key: img-server\n  - name: img-namespace\n    secret_ref:\n      name: ci-config\n      key: img-namespace\n...\n</code></pre> </li> <li> <p>Kickoff the pipeline by making a dummy commit:</p> <pre><code>echo \"\\n\" &gt;&gt; README.md\ngit add .\ngit commit -s -m \"Dummy commit\"\ngit push\n</code></pre> </li> <li> <p>The CI pipeline should kick off. Once complete, you will be able to test the deployed service by going to the service route (accessible from openshift Console, or by running <code>oc get route</code>).</p> </li> </ul>"},{"location":"labs/inventory-app/fast-track/#deploy-backend-for-frontend-bff","title":"Deploy backend for frontend (BFF)","text":"<ul> <li> <p>Create a new repository from the BFF Solution template.</p> <p>Warning</p> <p>In order to prevent naming collisions if you are running this as part of a workshop, chose the GitHub organization you have been invited to as <code>Owner</code> and name the repository <code>inv-bff-${UNIQUE_SUFFIX}</code>, replacing <code>${UNIQUE_SUFFIX}</code> with your team name or initials.</p> </li> <li> <p>Deploy this application with Tekton:</p> <p>Note</p> <p>You should have the <code>tkn</code>, <code>tkn pac</code> and <code>oc</code> CLIs installed. <code>oc</code> can be installed through the help section of your OpenShift console.</p> </li> <li> <p>In the OpenShift web console, click on the user ID on the top right, click on Copy login command and get the OpenShift login command, which includes a token.</p> </li> </ul> <p></p> <ul> <li> <p>Click on Display Token, copy the Login with the token. oc login command will log you in. Run the login command in your terminal:</p> <pre><code>oc login --token=&lt;OCP_TOKEN&gt; --server=&lt;OCP_SERVER&gt;\n</code></pre> </li> <li> <p>Move to your <code>inventory-${UNIQUE_SUFFIX}-dev</code> project created in previous lab:</p> <pre><code>export UNIQUE_SUFFIX=ns # CHANGEME\noc project inventory-${UNIQUE_SUFFIX}-dev\n</code></pre> </li> <li> <p>Clone the repo locally:</p> <pre><code>git clone https://github.com/cloud-design-patterns-journey/inv-bff-${UNIQUE_SUFFIX}.git\ncd inv-bff-${UNIQUE_SUFFIX}\n</code></pre> </li> <li> <p>Create the tekton pipeline for the backend service your new project:</p> <pre><code>oc adm policy add-scc-to-user privileged -z pipeline\ntkn pac create repository\n</code></pre> </li> </ul> <p>Note</p> <ul> <li><code>tkn pac create repository</code> assumes you have Pipelines-as-Code already setup on your cluster and Git provider. If you are running this lab as part of a workshop, this has been configured for you, make sure you use the provided GitHub organization when you create yout Git repository from template above.</li> <li><code>oc adm policy add-scc-to-user privileged -z pipeline</code> will make sure that the Tekton pipeline will be able to escalade privileges in your <code>inventory-${UNIQUE_SUFFIX}-dev</code> project/namespace.</li> </ul> <ul> <li> <p>In OpenShift console (Pipelines Section &gt; Pipelines &gt; Repositories), edit the newly created <code>Repository</code> YAML to add cluster specific configuration (e.g. image repository):</p> <pre><code>...\nspec:\n  params:\n  - name: img-server\n    secret_ref:\n      name: ci-config\n      key: img-server\n  - name: img-namespace\n    secret_ref:\n      name: ci-config\n      key: img-namespace\n...\n</code></pre> </li> <li> <p>Last step before kicking off the pipeline is to make sure our Kubernetes/OpenShift deployment will get the <code>SERVICE_URL</code> environment variable configured. To do so, create a secret and patch the deployment to use it as source for environment variables:</p> <pre><code>oc create secret generic inv-bff-${UNIQUE_SUFFIX}-config --from-literal=SERVICE_URL=http://inv-svc-${UNIQUE_SUFFIX}:8080\n</code></pre> </li> <li> <p>Update the Tekton <code>deploy</code> task in <code>.tekton/tasks.yaml</code> to set deployment environment variables from newly created secret:</p> .tekton/tasks.yaml<pre><code>...\n      echo \"Creating deployment $(params.app-name)\"\n      kubectl create deploy $(params.app-name) --image $(params.image) --port $(params.app-port)\n      kubectl set env --from=secret/$(params.app-name)-config deployment/$(params.app-name) # NEW LINE\n      kubectl expose deploy $(params.app-name) --port $(params.app-port)\n      oc expose svc $(params.app-name)\n...\n</code></pre> </li> <li> <p>After validation, commit and push the changes to git:     <pre><code>git add .\ngit commit -s -m \"Updates CI\"\ngit push\n</code></pre></p> </li> <li> <p>CI pipeline should be kicked off, you can test the hosted application once complete.</p> </li> </ul>"},{"location":"labs/inventory-app/fast-track/#deploy-frontend-microservice","title":"Deploy frontend microservice","text":"<ul> <li> <p>Create a new repository from the UI Solution template.</p> <p>Warning</p> <p>In order to prevent naming collisions if you are running this as part of a workshop, chose the GitHub organization you have been invited to as <code>Owner</code> and name the repository <code>inv-ui-${UNIQUE_SUFFIX}</code>, replacing <code>${UNIQUE_SUFFIX}</code> with your team name or initials.</p> </li> <li> <p>Deploy this application with Tekton:</p> <p>Note</p> <p>You should have the <code>tkn</code>, <code>tkn pac</code> and <code>oc</code> CLIs installed. <code>oc</code> can be installed through the help section of your OpenShift console.</p> </li> <li> <p>In the OpenShift web console, click on the user ID on the top right, click on Copy login command and get the OpenShift login command, which includes a token.</p> </li> </ul> <p></p> <ul> <li> <p>Click on Display Token, copy the Login with the token. oc login command will log you in. Run the login command in your terminal:</p> <pre><code>oc login --token=&lt;OCP_TOKEN&gt; --server=&lt;OCP_SERVER&gt;\n</code></pre> </li> <li> <p>Move to your <code>inventory-${UNIQUE_SUFFIX}-dev</code> project created in previous lab:</p> <pre><code>export UNIQUE_SUFFIX=ns # CHANGEME\noc project inventory-${UNIQUE_SUFFIX}-dev\n</code></pre> </li> <li> <p>Clone the repo locally:</p> <pre><code>git clone https://github.com/cloud-design-patterns-journey/inv-ui-${UNIQUE_SUFFIX}.git\ncd inv-ui-${UNIQUE_SUFFIX}\n</code></pre> </li> <li> <p>Create the tekton pipeline for the backend service your new project:</p> <pre><code>oc adm policy add-scc-to-user privileged -z pipeline\ntkn pac create repository\n</code></pre> </li> </ul> <p>Note</p> <ul> <li><code>tkn pac create repository</code> assumes you have Pipelines-as-Code already setup on your cluster and Git provider. If you are running this lab as part of a workshop, this has been configured for you, make sure you use the provided GitHub organization when you create yout Git repository from template above.</li> <li><code>oc adm policy add-scc-to-user privileged -z pipeline</code> will make sure that the Tekton pipeline will be able to escalade privileges in your <code>inventory-${UNIQUE_SUFFIX}-dev</code> project/namespace.</li> </ul> <ul> <li> <p>In OpenShift console (Pipelines Section &gt; Pipelines &gt; Repositories), edit the newly created <code>Repository</code> YAML to add cluster specific configuration (e.g. image repository):</p> <pre><code>...\nspec:\n  params:\n  - name: img-server\n    secret_ref:\n      name: ci-config\n      key: img-server\n  - name: img-namespace\n    secret_ref:\n      name: ci-config\n      key: img-namespace\n...\n</code></pre> </li> <li> <p>Last step before kicking off the pipeline is to make sure our Kubernetes/OpenShift deployment will get the <code>API_HOST</code> environment variable configured. To do so, create a secret and patch the deployment to use it as source for environment variables:</p> <pre><code>oc create secret generic inv-ui-${UNIQUE_SUFFIX}-config --from-literal=API_HOST=http://inv-bff-${UNIQUE_SUFFIX}:3000\n</code></pre> </li> <li> <p>Update the Tekton <code>deploy</code> task in <code>.tekton/tasks.yaml</code> to set deployment environment variables from newly created secret:</p> .tekton/tasks.yaml<pre><code>...\n      echo \"Creating deployment $(params.app-name)\"\n      kubectl create deploy $(params.app-name) --image $(params.image) --port $(params.app-port)\n      kubectl set env --from=secret/$(params.app-name)-config deployment/$(params.app-name) # NEW LINE\n      kubectl expose deploy $(params.app-name) --port $(params.app-port)\n      oc expose svc $(params.app-name)\n...\n</code></pre> </li> <li> <p>After validation, commit and push the changes to git:     <pre><code>git add .\ngit commit -s -m \"Updates CI\"\ngit push\n</code></pre></p> </li> <li> <p>CI pipeline should be kicked off, you can test the hosted application once complete.</p> </li> </ul>"},{"location":"labs/inventory-app/fast-track/#summary","title":"Summary","text":"<p>Congrats! You have now completed the Micro App Guide demonstrating the Inventory solution.</p>"},{"location":"labs/inventory-app/inventory-appid/","title":"Authentication with App ID","text":"<p>Securing Inventory App with App ID</p> <p>To secure the application we are using the capabilities available within the IBM Cloud platform to enable integration with AppID. With Openshift 3.11, a simple annotation was used on the ingress to enable Appid. In Openshift 4.x, Red Hat OpenShift on IBM Cloud annotations (ingress.bluemix.net/[annotation]) and NGINX annotations (nginx.ingress.kubernetes.io/[annotation_name]) are not supported for the router or the Ingress resource. With Openshift 4.x, AppID integration is enabled with SDKs.</p>"},{"location":"labs/inventory-app/inventory-appid/#prerequisites","title":"Prerequisites","text":"<p>The following prerequisites are required for AppID integration:  </p> <ul> <li>An instance of the App ID service:   In IBM Cloud Dashboard, go to \"Services\" and select the AppID instance.</li> </ul> <p></p> <ul> <li> <p>A set of service credentials:</p> <ul> <li>In AppID instance, go to \"Application\". </li> <li>Click on \"Add application\".</li> <li>Enter your application name </li> <li>Select the type as Regular web application.</li> <li>Click on Save to create the service credentials for your application.</li> </ul> <p></p> <ul> <li>After saving, your application credentials will get created.Click on the down Arrow at  the left end of your application name and get the credentials.</li> </ul> <p></p> </li> <li> <p><code>yarn</code> version 1.22.19 or higher.</p> </li> <li><code>node</code> version 16.16.0 or higher (it is recommended that you use an LTS version).</li> </ul> <p>Note</p> <p>To install <code>yarn</code> run the command <code>npm install -g yarn</code></p>"},{"location":"labs/inventory-app/inventory-appid/#enable-appid-in-the-solution","title":"Enable Appid in the solution","text":""},{"location":"labs/inventory-app/inventory-appid/#installation","title":"Installation","text":"<ul> <li>By using the command line, change to the directory that contains your Node.js app.</li> <li> <p>Install the AppID service and other dependencies.</p> <pre><code>yarn add ibmcloud-appid passport@0.5.2 express-session\n</code></pre> </li> <li> <p>Obtain your credentials by navigating to the Applications tab of the AppID dashboard as mentioned in Prerequisites.</p> </li> <li> <p>Obtain the application as mentioned in AppID Redirect Url Config.</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-appid/#create-binding-secret-for-appid-in-your-namespace","title":"Create binding secret for appid in your namespace","text":"<ul> <li>Login to the IBM Cloud cluster where your workshop-team-one ocp cluster resides.   <pre><code>ibmcloud login -u [username] -p [password]\n</code></pre></li> <li>Login to your ocp cluster using the oc cli.</li> </ul> <ul> <li> <p>Click on \"Copy Login Command\". It will redirect to a new page.  </p> </li> <li> <p>Click the display token link. Copy the \"Log in with this token\" command &amp; login to <code>oc</code> cli, it should look like this :</p> <pre><code>oc login --token=sha256~bfGcq7l6H3JHd9GwbNRaSsJ7cDAiLK5EPF4tbPQ-WfY --server=https://c108-e.eu-gb.containers.cloud.ibm.com:31718\n</code></pre> </li> <li> <p>Navigate to your namespace where you are running the inventory solution pipeline and create the binding secret for He the Appid instance on the cloud account   <pre><code>oc project &lt;PROJECT_NAME&gt;\nibmcloud oc cluster service bind --cluster workshop-team-one --namespace &lt;PROJECT_NAME&gt; --service workshop-team-one-appid\n</code></pre></p> </li> </ul> <p>Note</p> <p>Save the binding name, you will use it later</p>"},{"location":"labs/inventory-app/inventory-appid/#update-the-configuration-values-in-the-configuration-files","title":"Update the configuration values in the configuration files","text":"<ul> <li> <p>Put these credentials in server/config/mappings.json to be referred by application:    server/config/mappings.json<pre><code>{\n \"APPID_CONFIG\": \"\"{\\\"tenantId\\\":\\\"&lt;tenantId_value&gt;\\\",\\\"oauthServerUrl\\\":\\\"&lt;oauthServer_URL&gt;\\\",\\\"clientId\\\": \\\"&lt;ClientID_value&gt;\\\", \\\"secret\\\": \\\"&lt;secret_value&gt;\\\"}\",\n \"application_url\":\"&lt;openshift_appln_route_url&gt;\"\n}\n</code></pre></p> </li> <li> <p>Add the following parameter in <code>values.yaml</code> along with its value:    chart/base/values.yaml<pre><code>appidBinding: &lt;BINDING_NAME&gt;\n</code></pre></p> </li> </ul>"},{"location":"labs/inventory-app/inventory-appid/#adding-the-dependencies","title":"Adding the dependencies","text":"<ul> <li>Add the following require definitions to your <code>server/server.js</code>:     server/server.js<pre><code>const express = require('express');\nconst session = require('express-session')\nconst passport = require('passport');\nconst WebAppStrategy = require(\"ibmcloud-appid\").WebAppStrategy;\nconst CALLBACK_URL = \"/ibm/cloud/appid/callback\";\nconst appidConfig = require(\"./config/mappings.json\");\n</code></pre></li> </ul>"},{"location":"labs/inventory-app/inventory-appid/#activate-the-appid-integration","title":"Activate the appid integration","text":"<ul> <li> <p>In server.js, set up your express app to use express-session middleware.    server/server.js<pre><code>const app = express();\n\nconst appidcfg = appidConfig.APPID_CONFIG;\n\napp.use(\n  session({\n        secret: appidcfg.secret,\n        resave: true,\n        saveUninitialized: true\n  })\n);\napp.use(passport.initialize());\napp.use(passport.session());\n</code></pre></p> </li> <li> <p>In the same file, initialize the SDK using the information obtained in the previous steps.    server/server.js<pre><code>passport.use(\n  new WebAppStrategy({\n    tenantId: appidcfg.tenantId,\n    clientId: appidcfg.clientId,\n    secret: appidcfg.secret,\n    oauthServerUrl: appidcfg.oAuthServerUrl,\n    redirectUri: appidConfig.application_url + CALLBACK_URL\n  })\n);\n</code></pre></p> </li> <li> <p>In the same file, configure passport with serialization and deserialization. This configuration step is required for authenticated session persistence across HTTP requests. For more information, see the passport docs server/server.js<pre><code>passport.serializeUser(function(user, cb) {\n  cb(null, user);\n});\npassport.deserializeUser(function(obj, cb) {\n  cb(null, obj);\n});\n</code></pre></p> </li> <li> <p>Add the following code to your server.js to issue the service redirects.     server/server.js<pre><code>app.get(CALLBACK_URL, passport.authenticate(WebAppStrategy.STRATEGY_NAME));\napp.use(passport.authenticate(WebAppStrategy.STRATEGY_NAME ));\n</code></pre></p> </li> </ul>"},{"location":"labs/inventory-app/inventory-appid/#adding-environment-variables-to-deploymentyaml","title":"Adding environment variables to <code>deployment.yaml</code>","text":"<ul> <li>Open the <code>deployment.yaml</code> file and add environment variables that use those values to the top of the existing <code>env</code> block:   chart/base/templates/deployment.yaml<pre><code>- name: APPID_CONFIG\n  valueFrom:\n     secretKeyRef:\n        name: {{ .Values.appidBinding | quote }}\n        key: binding\n</code></pre></li> </ul>"},{"location":"labs/inventory-app/inventory-appid/#appid-redirect-url-config","title":"AppID redirect url config","text":"<ul> <li> <p>Get the ingress for the UI component by running <code>igc ingress -n inventory-${UNIQUE_SUFFIX}-dev</code>.</p> </li> <li> <p>Open the IBM Cloud resource list - <code>https://cloud.ibm.com/resources</code></p> </li> <li> <p>Open the AppID instance to the <code>Manage Authentication</code> -&gt; <code>Authentication Settings</code> view</p> <p></p> </li> <li> <p>Add the redirect url for the application to the web redirect URLs. The redirect url will have the following form:</p> <p><code>{ingress url}/ibm/cloud/appid/callback</code></p> <p>e.g. <code>https://inventory-manangement-ui-dev.sms-test-oc-cluster.us-east.containers.appdomain.cloud/ibm/cloud/appid/callback</code></p> </li> </ul>"},{"location":"labs/inventory-app/inventory-appid/#add-users-to-appid","title":"Add users to AppID","text":"<ul> <li> <p>Open the AppID instance to <code>Cloud Directory</code> -&gt; <code>Users</code></p> <p></p> </li> <li> <p>Add yourself as a user with an email address, name, and password#</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-appid/#commit-and-push-the-changes","title":"Commit and push the changes","text":"<ul> <li>Commit your local changes and push them to your remote repository   <pre><code>git add .\ngit commit -m \"Added appid\"\ngit push\n</code></pre></li> <li>Your previously defined pipeline should be launched and the new app should be deployed afterwards</li> </ul>"},{"location":"labs/inventory-app/inventory-appid/#access-the-ui","title":"Access the UI","text":"<ul> <li> <p>Open a browser to the UI Application URL</p> </li> <li> <p>You should be met with the AppID login screen. (This screen can be customized from the AppID service console but for now we are showing the default screen.)</p> <p></p> </li> <li> <p>Provide the email address and password you configured in the previous steps. You should be granted access to the UI.</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-application/","title":"Introduction","text":"<p>Develop an example application with a three-tier microservices architecture and deploy it into Red Hat OpenShift on premises, on AWS, Azure or IBM Cloud. This OpenShift development environment has been pre-configured with a sample SDLC (Software Delivery Life Cycle).</p>"},{"location":"labs/inventory-app/inventory-application/#business-need","title":"Business Need","text":"<p>In this guide, imagine you have completed an Enterprise Design Thinking Workshop and the result is an MVP statement that defines the desired business outcomes. Use the steps below to help deliver this MVP quickly while following Garage Method best practices.</p>"},{"location":"labs/inventory-app/inventory-application/#mvp-statement","title":"MVP Statement","text":"<p>An MVP is a first hill. Here's the hill statement for the MVP we're going to build:</p> <ul> <li> <p>Who: Distribution employees in each of the regional warehouses</p> </li> <li> <p>What: A secure web application that enables easy access to list of product SKU inventory levels and inventory locations</p> </li> <li> <p>Wow: Make the system appealing and easy to use. Develop it quickly as a minimum viable product. Use the latest managed container runtimes and DevOps best practices to enable post MVP feature improvements. Simulate a release to a Test environment.</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-application/#architecture","title":"Architecture","text":"<p>We will build an application that is made up of microservices in three-tier architecture. Each tier encapsulates a clean separation of concerns. Each app microservice component will be modelled using microservices and use a number of polyglot programming languages and frameworks. Data will be stored in a NoSQL Database.</p> <p></p>"},{"location":"labs/inventory-app/inventory-application/#user-interface","title":"User interface","text":"<p>The user experience for the application has been designed by the design team and this drives the requirements for the development team.</p>"},{"location":"labs/inventory-app/inventory-application/#technical-requirements","title":"Technical Requirements","text":"<p>The Micro services should adhere to the following technical requirements:</p> <ul> <li>Microservices<ul> <li>Stateless</li> <li>REST APIs</li> <li>Polyglot</li> </ul> </li> <li>DevOps with CI/CD (continuous integration and continuous delivery) <ul> <li>Use in cluster CI technology to be efficient and secure</li> <li>Use latest GitOps best practices</li> <li>Monitoring and logging</li> <li>Code analysis</li> <li>App security</li> </ul> </li> <li>Deployed to Red Hat OpenShift cluster which is based on Kubernetes open source technology</li> <li>Follow the Carbon Design System user experience</li> </ul>"},{"location":"labs/inventory-app/inventory-application/#guide","title":"Guide","text":"<p>You will approach creating the microservices bottom up, meaning you will start by creating the backend microservice that manages integration with the data persistence and then build out the digital channel using a backend for frontend pattern. Finally, you will add a web UI to the solution.</p>"},{"location":"labs/inventory-app/inventory-bff/","title":"BFF","text":""},{"location":"labs/inventory-app/inventory-bff/#develop-and-deploy-the-bff-component-of-the-inventory-application","title":"Develop and deploy the BFF component of the inventory application","text":"<p>The Inventory BFF's role in the architecture is to act as an orchestrator between the core business services and the specific digital channel it is focused on supporting. This class article will give you more detail about the Backend For Frontend architectural pattern and the benefits.</p> Backend For Frontend pattern Overview - source <p>The Inventory solution will use GraphQL for its BFF layer, which enables the API to be dynamically controlled from the client using API queries. Follow the steps below to get started.</p>"},{"location":"labs/inventory-app/inventory-bff/#setup","title":"Setup","text":"<p>Note</p> <p>Following this section means you have already deployed and configured the backend service from the previous step. Your OpenShift cluster should have the <code>inventory-${UNIQUE_SUFFIX}-dev</code> project (with <code>${UNIQUE_SUFFIX}</code> as your team name or initials), that has been configured with <code>ci-config</code> and <code>registry-config</code> secrets during previous lab.</p>"},{"location":"labs/inventory-app/inventory-bff/#create-your-openshift-project-git-repository-and-ci-pipeline","title":"Create your OpenShift project, Git Repository and CI pipeline","text":"<ul> <li> <p>Create a new repository from the Typescript GraphQL template.</p> <p>Warning</p> <p>In order to prevent naming collisions if you are running this as part of a workshop, chose the GitHub organization you have been invited to as <code>Owner</code> and name the repository <code>inv-bff-${UNIQUE_SUFFIX}</code>, replacing <code>${UNIQUE_SUFFIX}</code> with your team name or initials.</p> </li> <li> <p>Deploy this application with Tekton:</p> <p>Note</p> <p>You should have the <code>tkn</code>, <code>tkn pac</code> and <code>oc</code> CLIs installed. <code>oc</code> can be installed through the help section of your OpenShift console.</p> <ul> <li>In the OpenShift web console, click on the user ID on the top right, click on Copy login command and get the OpenShift login command, which includes a token.</li> </ul> <p></p> <ul> <li>Click on Display Token, copy the Login with the token. oc login command will log you in. Run the login command in your terminal:</li> </ul> <pre><code>oc login --token=&lt;OCP_TOKEN&gt; --server=&lt;OCP_SERVER&gt;\n</code></pre> <ul> <li>Move to your <code>inventory-${UNIQUE_SUFFIX}-dev</code> project created in previous lab:</li> </ul> <pre><code>export UNIQUE_SUFFIX=ns # CHANGEME\noc project inventory-${UNIQUE_SUFFIX}-dev\n</code></pre> <ul> <li>Clone the repo locally:</li> </ul> <pre><code>git clone https://github.com/cloud-design-patterns-journey/inv-bff-${UNIQUE_SUFFIX}.git\ncd inv-bff-${UNIQUE_SUFFIX}\n</code></pre> <ul> <li>Create the tekton pipeline for the backend service your new project:</li> </ul> <pre><code>oc adm policy add-scc-to-user privileged -z pipeline\ntkn pac create repository\n</code></pre> <p>Note</p> <ul> <li><code>tkn pac create repository</code> assumes you have Pipelines-as-Code already setup on your cluster and Git provider. If you are running this lab as part of a workshop, this has been configured for you, make sure you use the provided GitHub organization when you create yout Git repository from template above.</li> <li><code>oc adm policy add-scc-to-user privileged -z pipeline</code> will make sure that the Tekton pipeline will be able to escalade privileges in your <code>inventory-${UNIQUE_SUFFIX}-dev</code> project/namespace.</li> </ul> <ul> <li>In OpenShift console (Pipelines Section &gt; Pipelines &gt; Repositories), edit the newly created <code>Repository</code> YAML to add cluster specific configuration (e.g. image repository):</li> </ul> <pre><code>...\nspec:\n  params:\n    - name: img-server\n      secret_ref:\n        name: ci-config\n        key: img-server\n    - name: img-namespace\n      secret_ref:\n        name: ci-config\n        key: img-namespace\n...\n</code></pre> </li> </ul>"},{"location":"labs/inventory-app/inventory-bff/#setup-your-development-environment","title":"Setup your development environment","text":"<ol> <li>Clone the project and open it using your favorite text editor or IDE (Visual Studio Code, Atom...).</li> <li>You are now ready to modify the application!</li> </ol>"},{"location":"labs/inventory-app/inventory-bff/#create-the-rest-interface","title":"Create the REST interface","text":"<p>The controller provides the REST interface for our BFF. The template uses the <code>typescript-rest</code> package to simplify the tasks required to create a controller.</p> <p>Since we will be developing this microservice following the Test Driven Development approach, we are first going to create the test for our <code>stock-items</code> controller.</p> <ul> <li> <p>Start the tests by running the following command in a new terminal that you will keep running while running the lab:     <pre><code>npm i\nnpm run tdd\n</code></pre></p> </li> <li> <p>Create the controller test:     test/controllers/stock-items.controller.spec.ts<pre><code>import * as request from 'supertest';\nimport { Test, TestingModule } from '@nestjs/testing';\nimport { INestApplication } from '@nestjs/common';\nimport { AppModule } from '../../src/app.module';\n\ndescribe('stock-item.controller', () =&gt; {\n\n    let app: INestApplication;\n    beforeEach(async () =&gt; {\n        const moduleFixture: TestingModule = await Test.createTestingModule({\n        imports: [AppModule],\n        }).compile();\n\n        app = moduleFixture.createNestApplication();\n        await app.init();\n    });\n\n    test('canary verifies test infrastructure', () =&gt; {\n        expect(true).toEqual(true);\n    });\n\n    describe('given GET /stock-items', () =&gt; {\n        describe('when service is successful', () =&gt; {\n            test('then return 200 status', async () =&gt; {\n                return request(app.getHttpServer()).get('/stock-items').expect(200);\n            });\n\n            test('then should return an empty array', async () =&gt; {\n                return request(app.getHttpServer()).get('/stock-items').expect([]);\n            });\n        });\n    });\n});\n</code></pre></p> </li> <li> <p>Notice that tests are failing.</p> </li> <li> <p>Create the controller component:     src/controllers/stock-items.controller.ts<pre><code>import { Controller, Get } from '@nestjs/common';\n\n@Controller('stock-items')\nexport class StockItemsController {\n\n    @Get()\n    async listStockItems(): Promise&lt;any[]&gt; {\n        return [];\n    }\n}\n</code></pre></p> </li> <li> <p>Add the controller to the controllers <code>index.ts</code>. (Using <code>index.ts</code> is a good way to manage which components are exposed by a component and provide a good way to load the modules that will be injected into other components):     src/controllers/index.ts<pre><code>import { HelloWorldController } from './hello-world';\nimport { StockItemsController } from './stock-items.controller';\n\nexport * from './hello-world';\nexport * from './stock-items.controller';\n\nexport const controllers = [HelloWorldController, StockItemsController];\n</code></pre></p> </li> <li> <p>Start the service to see it running:     <pre><code>npm start\n</code></pre></p> </li> <li> <p>Open a browser to <code>http://localhost:3000/stock-items</code> to see the app</p> </li> <li> <p>Push the changes we've made to the repository:     <pre><code>git add .\ngit commit -s -m \"Adds stock items controller\"\ngit push\n</code></pre></p> </li> <li> <p>CI pipeline should be kicked off, you can test the hosted application once complete.</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-bff/#update-the-controller-to-call-a-service","title":"Update the controller to call a service","text":"<p>The pattern recommended for the REST controllers is to let it focus on translating REST protocols into javascript and to put the business logic in a separate service component.</p> <p>The pattern recommended for the REST controllers is to let it focus on translating REST protocols into javascript and to put the business logic in a separate service component.</p> <ul> <li> <p>Add a StockItem model that contains the values needed for the UI:     src/models/stock-item.model.ts<pre><code>import { Field, ObjectType } from \"@nestjs/graphql\";\n\nexport interface StockItemModel {\n    id: string;\n    name: string;\n    stock: number;\n    unitPrice: number;\n    manufacturer: string;\n    picture: string;\n}\n\n@ObjectType({ description: 'stock-item' })\nexport class StockItem implements StockItemModel {\n    @Field()\n    id: string;\n    @Field()\n    name: string;\n    @Field()\n    stock: number;\n    @Field()\n    unitPrice: number;\n    @Field()\n    manufacturer: string;\n    @Field()\n    picture: string;\n}\n</code></pre></p> </li> <li> <p>Register the model with the <code>index.ts</code> file in the models directory. Append this to end of the file:     src/models/index.ts<pre><code>...\nexport * from './stock-item.model';\n</code></pre></p> </li> <li> <p>Define an abstract class to provide the interface for our API:     src/services/stock-items/stock-items.api.ts<pre><code>import { StockItemModel } from '../../models';\n\nexport abstract class StockItemsApi {\n    abstract listStockItems(): Promise&lt;StockItemModel[]&gt;;\n}\n</code></pre></p> <p>Note</p> <p>Why an abstract class and not an interface? TypeScript introduces both abstract classes and interfaces. Abstract classes can be used and they have the quirky behavior in TypeScript allowing them to either be <code>extended</code> like a class or <code>implemented</code> like an interface.</p> </li> <li> <p>Lets create an implementation that will provide mock data for now. Add a <code>stock-items-mock.service</code> to services:     src/services/stock-items/stock-items-mock.service.ts<pre><code>import { Injectable } from '@nestjs/common';\nimport { StockItemsApi } from './stock-items.api';\nimport { StockItemModel } from '../../models';\n\n@Injectable()\nexport class StockItemsMockService implements StockItemsApi {\nasync listStockItems(): Promise&lt;StockItemModel[]&gt; {\n        return [\n            {\n                id: \"1\",\n                name: \"Self-sealing stem bolt\",\n                stock: 10,\n                unitPrice: 10.5,\n                picture: \"https://via.placeholder.com/32.png\",\n                manufacturer: \"Bajor Galactic\"\n            },\n            {\n                id: \"2\",\n                name: \"Heisenberg compensator\",\n                stock: 20,\n                unitPrice: 20.0,\n                picture: \"https://via.placeholder.com/32.png\",\n                manufacturer: \"Federation Imports\"\n            },\n            {\n                id: \"3\",\n                name: \"Tooth sharpener\",\n                stock: 30,\n                unitPrice: 5.25,\n                picture: \"https://via.placeholder.com/32.png\",\n                manufacturer: \"Farenginar Exploits\"\n            }\n        ];\n    }\n}\n</code></pre></p> </li> <li> <p>Create a <code>src/services/stock-items/index.ts</code> to reference above classes:</p> src/services/stock-items/index.ts<pre><code>import {Provider} from \"@nestjs/common\";\n\nimport { StockItemsApi } from './stock-items.api';\nimport { StockItemsMockService } from './stock-items-mock.service';\n\nexport { StockItemsMockService, StockItemsApi };\n\nexport const provider: Provider = {\n    provide: StockItemsApi,\n    useClass: StockItemsMockService,\n};\n</code></pre> </li> <li> <p>Update the <code>src/services/providers.ts</code> file to reference the new service:     src/services/providers.ts<pre><code>import { Provider } from \"@nestjs/common\";\nimport { provider as helloWorldProvider } from \"./hello-world\";\nimport { StockItemsMockService, StockItemsApi, provider as stockItemsProvider } from \"./stock-items\";\n\nexport * from './hello-world';\n\nexport const providers: Provider[] = [helloWorldProvider, stockItemsProvider];\nexport { StockItemsApi, StockItemsMockService };\n</code></pre></p> </li> <li> <p>Update the controller test to inject the service into the controller and to return the value from the service:     test/controllers/stock-items.controller.spec.ts<pre><code>import * as request from 'supertest';\nimport { Test, TestingModule } from '@nestjs/testing';\nimport { INestApplication } from '@nestjs/common';\nimport { AppModule } from '../../src/app.module';\nimport { StockItemsApi } from '../../src/services';\n\n\nconst mockResult = [\n    {\n        id: \"1\",\n        name: \"Self-sealing stem bolt\",\n        stock: 10,\n        unitPrice: 10.5,\n        picture: \"https://via.placeholder.com/32.png\",\n        manufacturer: \"Bajor Galactic\"\n    },\n    {\n        id: \"2\",\n        name: \"Heisenberg compensator\",\n        stock: 20,\n        unitPrice: 20.0,\n        picture: \"https://via.placeholder.com/32.png\",\n        manufacturer: \"Federation Imports\"\n    },\n    {\n        id: \"3\",\n        name: \"Tooth sharpener\",\n        stock: 30,\n        unitPrice: 5.25,\n        picture: \"https://via.placeholder.com/32.png\",\n        manufacturer: \"Farenginar Exploits\"\n    }\n];\n\ndescribe('stock-item.controller', () =&gt; {\n\n    let app: INestApplication;\n    let stockItemsService = { listStockItems: () =&gt; mockResult };\n\n    beforeEach(async () =&gt; {\n\n        const moduleFixture: TestingModule = await Test.createTestingModule({\n            imports: [AppModule],\n        })\n            .overrideProvider(StockItemsApi)\n            .useValue(stockItemsService)\n            .compile();\n\n        app = moduleFixture.createNestApplication();\n        await app.init();\n    });\n\n    test('canary verifies test infrastructure', () =&gt; {\n        expect(true).toEqual(true);\n    });\n\n    describe('given GET /stock-items', () =&gt; {\n        describe('when service is successful', () =&gt; {\n            test('then return 200 status', async () =&gt; {\n                return request(app.getHttpServer()).get('/stock-items').expect(200);\n            });\n\n            test('then should return an empty array', async () =&gt; {\n                return request(app.getHttpServer()).get('/stock-items').expect(mockResult);\n            });\n        });\n    });\n});\n</code></pre></p> </li> <li> <p>Update the controller to inject the service and use it:     src/controllers/stock-items.controller.ts<pre><code>import { Controller, Get, HttpException } from '@nestjs/common';\n\nimport { StockItemsApi } from '../services';\n\n@Controller('stock-items')\nexport class StockItemsController {\n    constructor(private readonly service: StockItemsApi) { }\n\n    @Get()\n    async listStockItems(): Promise&lt;any[]&gt; {\n        try {\n            return await this.service.listStockItems();\n        } catch (err) {\n            throw new HttpException(err, 502);\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>Start the service     <pre><code>npm start\n</code></pre></p> </li> <li> <p>Access the running service. This service runs on port <code>3000</code>:</p> </li> <li> <p>Open a browser to <code>http://localhost:3000/stock-items</code> to see the app</p> </li> <li> <p>Push the changes we've made to the repository:     <pre><code>git add .\ngit commit -s -m \"Adds a mock service implementation\"\ngit push\n</code></pre></p> </li> <li> <p>CI pipeline should be kicked off, you can test the hosted application once complete.</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-bff/#add-a-graphql-implementation-of-stock-items","title":"Add a GraphQL implementation of Stock Items","text":"<p>The GraphQL template supports both REST and GraphQL APIs for accessing backend services. We have created a REST controller to expose the results from the service and now we will do the same for GraphQL.</p> <ul> <li> <p>Add a <code>stock-item</code> GraphQL resolver in the <code>resolvers</code> directory:     src/resolvers/stock-items/stock-items.resolver.ts<pre><code>import { Query, Resolver } from \"@nestjs/graphql\";\n\nimport { StockItem, StockItemModel } from \"../../models\";\nimport { StockItemsApi } from \"../../services\";\n\n@Resolver(of =&gt; StockItem)\nexport class StockItemResolver {\n    constructor(private readonly service: StockItemsApi) { }\n\n    @Query(returns =&gt; [StockItem])\n    async stockItems(): Promise&lt;StockItemModel[]&gt; {\n        return this.service.listStockItems();\n    }\n}\n</code></pre></p> </li> <li> <p>Add the stock-items resolver to <code>index.ts</code> in the <code>stock-items</code> resolver directory:     src/resolvers/stock-items/index.ts<pre><code>export * from './stock-items.resolver';\n</code></pre></p> </li> <li> <p>Reference the <code>StockItemResolver</code> in <code>src/resolvers/providers.ts</code>:     src/resolvers/providers.ts<pre><code>import {Provider} from \"@nestjs/common\";\nimport {HelloWorldResolver} from \"./hello-world\";\nimport {StockItemResolver} from \"./stock-items\";\n\nexport * from './hello-world';\nexport * from './stock-items';\n\nexport const providers: Provider[] = [HelloWorldResolver, StockItemResolver]\n</code></pre></p> </li> <li> <p>Start the service:     <pre><code>npm start\n</code></pre></p> </li> <li> <p>Verify that the that the resolver is available using the Graph QL browser provided by the template:</p> </li> <li> <p>In your Browser, open GraphQL playground: <code>http://localhost:3000/graphql</code></p> </li> <li> <p>Run the query <code>query { stockItems { name } }</code></p> </li> <li> <p>Push the changes we've made to the repository:     <pre><code>git add .\ngit commit -s -m \"Adds a graphql interface\"\ngit push\n</code></pre></p> </li> <li> <p>CI pipeline should be kicked off, you can test the hosted application once complete.</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-bff/#create-a-service-implementation-that-calls-the-microservice","title":"Create a service implementation that calls the microservice","text":"<ul> <li> <p>Install required <code>superagent</code> module:</p> <pre><code>npm i superagent\n</code></pre> </li> <li> <p>Add a <code>src/services/stock-items/stock-items.service.ts</code> service implementation that we'll configure to target our actual stock items Java based service:     src/services/stock-items/stock-items.service.ts<pre><code>import { Injectable } from '@nestjs/common';\nimport { StockItemsApi } from './stock-items.api';\nimport { StockItemModel } from '../../models';\nimport { get } from 'superagent';\nimport { ConfigService } from '@nestjs/config';\n\nclass StockItem {\n    'id'?: string;\n    'manufacturer'?: string;\n    'picture'?: string;\n    'name'?: string;\n    'price'?: number;\n    'stock'?: number;\n}\n\n@Injectable()\nexport class StockItemsService implements StockItemsApi {\n    constructor(private configService: ConfigService) { }\n\n    async listStockItems(): Promise&lt;StockItemModel[]&gt; {\n        const serviceUrl = this.configService.get&lt;string&gt;('SERVICE_URL');\n        return new Promise((resolve, reject) =&gt; {\n            get(`${serviceUrl}/stock-items`)\n                .set('Accept', 'application/json')\n                .then(res =&gt; {\n                    resolve(this.mapStockItems(res.body));\n                })\n                .catch(err =&gt; {\n                    reject(err);\n                });\n        });\n    }\n\n    mapStockItems(data: StockItem[]): StockItemModel[] {\n        return data.map(this.mapStockItem);\n    }\n\n    mapStockItem(item: StockItem): StockItemModel {\n        return {\n            id: item.id,\n            name: item.name,\n            stock: item.stock,\n            unitPrice: item.price,\n            picture: item.picture ?? 'https://via.placeholder.com/32.png',\n            manufacturer: item.manufacturer,\n        };\n    }\n}\n</code></pre></p> <p>Note</p> <p>From now on, we'll need a <code>SERVICE_URL</code> environment variable to be used as base URL to reach our Java microservice.</p> </li> <li> <p>Update <code>src/services/stock-items/index.ts</code> to reference and use our newly created service as provider:     src/services/stock-items/index.ts<pre><code>import {Provider} from \"@nestjs/common\";\n\nimport { StockItemsApi } from './stock-items.api';\nimport { StockItemsMockService } from './stock-items-mock.service';\nimport { StockItemsService } from './stock-items.service';\n\nexport { StockItemsMockService, StockItemsApi, StockItemsService };\n\nexport const provider: Provider = {\n    provide: StockItemsApi,\n    useClass: StockItemsService,\n};\n</code></pre></p> </li> <li> <p>Test the application again by setting <code>SERVICE_URL</code> before running the app:     <pre><code>export SERVICE_URL=http://localhost:8080 # CHANGEME\nnpm start\n</code></pre></p> </li> <li> <p>Last step before checking out our changes to git is to make sure our Kubernetes/OpenShift deployment will get the <code>SERVICE_URL</code> environment variable configured. To do so, create a secret and patch the deployment to use it as source for environment variables:</p> <pre><code>oc create secret generic inv-bff-${UNIQUE_SUFFIX}-config --from-literal=SERVICE_URL=http://inv-svc-${UNIQUE_SUFFIX}:8080\nkubectl set env --from=secret/inv-bff-${UNIQUE_SUFFIX}-config deployment/inv-bff-${UNIQUE_SUFFIX}\n</code></pre> </li> <li> <p>After validation, commit and push the changes to git:     <pre><code>git add .\ngit commit -s -m \"Adds service implementation\"\ngit push\n</code></pre></p> </li> <li> <p>CI pipeline should be kicked off, you can test the hosted application once complete.</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-mongodb/","title":"Database with MongoDB","text":""},{"location":"labs/inventory-app/inventory-mongodb/#add-a-mongodb-integration-to-your-backend-service","title":"Add a MongoDB integration to your backend service","text":""},{"location":"labs/inventory-app/inventory-mongodb/#create-a-mongodb-instance","title":"Create a MongoDB instance","text":"On OpenShiftOn IBM CloudBYO MongoDB <p>Install your self managed MongoDB instance using Helm Charts.</p> <ul> <li> <p>Login to your OpenShift cluster on a terminal and choose your development project.</p> </li> <li> <p>Create a <code>mongodb.values.yaml</code> with the following content mongodb.values.yaml<pre><code>podSecurityContext:\n  enabled: false\ncontainerSecurityContext:\n  enabled: false\nauth:\n  usernames:\n    - myuser\n  passwords:\n    - mypassword\n  databases:\n    - inventory-db\n</code></pre> You can change the username, password and database name to your liking.</p> </li> <li> <p>Run the following commands, it will install a Helm chart on your project, make sure to have <code>helm</code> installed locally. <pre><code>$ helm repo add bitnami https://charts.bitnami.com/bitnami\n$ helm install mongodb bitnami/mongodb -f mongodb.values.yaml\n</code></pre></p> </li> <li>Head over to your OpenShift console on the Topology perspective, you should the database created on your project. </li> <li>The Helm chart creates a secret holding MongoDB passwords, for consistency of this tutorial we will be creating another secret holding the same information, formatted in another way.   Run the following command :   <pre><code>$ oc create secret generic --from-literal=MONGODB_HOST=mongodb --from-literal=MONGODB_PORT=27017 --from-literal=MONGODB_USER=myuser --from-literal=MONGODB_PASSWORD=mypassword --from-literal=MONGODB_DATABASE=inventory-db mongodb-access\n</code></pre>   You should see the created secret <code>mongodb-access</code> on your OpenShift console : </li> </ul> <p>Warning</p> <p>The IBM Cloud service enforces SSL certificates usage to access the instance, however this is not covered in this tutorial, you can find the documentation for it here.</p> <p>Provision a MongoDB instance using the Databases for MongoDB service on IBM Cloud.</p> <ul> <li> <p>Log into the IBM Cloud console and look for the Databases for MongoDB service.</p> </li> <li> <p>Configure it to your needs and create the instance. </p> </li> <li> <p>After your instance has provisioned, create a Service Credential to have access to your MongoDB instance.    The service credential should contain information to login to the instance. We will look for the database, the hostname, the username, the password and a base64 encoded certificate.   Decode the certificate, and create an OpenShift secret holding these values :   <pre><code>oc create secret generic --from-literal=MONGODB_HOST=&lt;HOST&gt; --from-literal=MONGODB_PORT=&lt;PORT&gt; --from-literal=MONGODB_USER=&lt;USER&gt; --from-literal=MONGODB_DATABASE=&lt;DATABASE&gt; --from-literal=MONGODB_PASSWORD=&lt;PASSWORD&gt; --from-literal=MONGODB_CERT=&lt;DECODED_CERT&gt; mongodb-access\n</code></pre>   You can also do this from the OpenShift console : </p> </li> </ul> <p>Create your own MongoDB instance on any other cloud platform and bring the login credentials.</p> <p>Login to your OpenShift cluster and create a secret using the following command:   <pre><code>$ oc create secret generic --from-literal=MONGODB_HOST=&lt;HOST&gt; --from-literal=MONGODB_PORT=&lt;PORT&gt; --from-literal=MONGODB_USER=&lt;USER&gt; --from-literal=MONGODB_PASSWORD=&lt;PASSWORD&gt; --from-literal=MONGODB_DATABASE=&lt;DATABASE&gt; mongodb-access\n</code></pre>   Fill out the placeholders <code>&lt;HOST&gt;</code>, <code>&lt;USER&gt;</code>, <code>&lt;PASSWORD&gt;</code> and <code>&lt;DATABASE&gt;</code> with your own MongoDB instance's credentials.</p>"},{"location":"labs/inventory-app/inventory-mongodb/#fill-in-the-database-with-mock-data","title":"Fill in the database with mock data","text":"<ul> <li> <p>To help create test JSON data we are going to supply a template to the JSON Generator tool, this helps when creating dummy data for testing. Navigate to the following link https://www.json-generator.com/.</p> </li> <li> <p>Replace the default template with following template. This will enable a 100 records of test data to be created to represent a products database. Click on the Generate button.  <pre><code>[\n   '{{repeat(100)}}',\n   {\n     _id: '{{objectId()}}',\n     manufacturer: '{{company().toUpperCase()}}',\n     name:  '{{lorem(3, \"words\")}}',\n     price: '{{floating(10, 1000, 2, \"0.00\")}}',\n     stock: '{{integer(1, 100)}}'\n   }\n ]\n</code></pre></p> </li> <li>Connect to your MongoDB instance, create a new collection called <code>stockItem</code> in your database and insert the generated data.</li> </ul>"},{"location":"labs/inventory-app/inventory-mongodb/#enable-database-in-the-solution","title":"Enable database in the solution","text":"<p>If you are starting from the solution, use the following steps to enable the database.</p> <p>Update the gradle config to include mongodb dependencies</p> <ul> <li>Head over to the <code>gradle</code> and create the following <code>build-mongodb.gradle</code> file:  gradle/build-mongodb.gradle<pre><code>dependencies {\n  implementation group: 'org.springframework.boot', name: 'spring-boot-starter-data-mongodb', version: '2.7.1'\n  implementation group: 'org.springframework.boot', name: 'spring-boot-starter-data-jpa', version: '2.7.1'\n}\n</code></pre></li> <li>On the <code>build.gradle</code> file, add the following line :  build.gradle<pre><code>apply from: 'gradle/build-mongodb.gradle'\n</code></pre></li> <li>Run <code>./gradlew build --refresh-dependencies</code> to validate the changes and load the libraries.</li> </ul> <p>Update application configuration to connect to database</p> <ul> <li>On the <code>src/main/resources/application.yml</code> file, update the <code>spring</code> by adding the content as such.  src/main/resources/application.yml<pre><code>spring:\n  data:\n   mongodb:\n     username: \"${MONGODB_USERNAME:&lt;USERNAME&gt;}\"\n     password: \"${MONGODB_PASSWORD:&lt;PASSWORD&gt;}\"\n     database: \"${MONGODB_DATABASE:&lt;DATABASE&gt;}\"\n     authentication-database: \"${MONGODB_DATABASE:&lt;DATABASE&gt;}\"\n     port: \"${MONGODB_PORT:&lt;PORT&gt;}\"\n     host: \"${MONGODB_HOST:&lt;HOST&gt;}\"\n  autoconfigure:\n   exclude: org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration\n</code></pre>    Replace the placeholders with your database instance values.</li> </ul> <p>Update the configuration values in the Helm chart</p> <ul> <li>Open the <code>values.yaml</code> file and add the following value : </li> </ul> <p>chart/base/values.yaml<pre><code>mongodbAccess=mongodb-access\n</code></pre>  - Open the <code>deployment.yaml</code> file and add the following environment variables :</p> chart/base/templates/deployment.yaml<pre><code>env:\n  - name: MONGODB_USERNAME\n    valueFrom:\n      secretKeyRef:\n        name: {{ .Values.mongodbAccess | quote }}\n        key: MONGODB_USERNAME\n  - name: MONGODB_PASSWORD\n    valueFrom:\n      secretKeyRef:\n        name: {{ .Values.mongodbAccess | quote }}\n        key: MONGODB_PASSWORD\n  - name: MONGODB_DATABASE\n    valueFrom:\n      secretKeyRef:\n        name: {{ .Values.mongodbAccess | quote }}\n        key: MONGODB_DATABASE\n  - name: MONGODB_PORT\n    valueFrom:\n      secretKeyRef:\n        name: {{ .Values.mongodbAccess | quote }}\n        key: MONGODB_PORT\n  - name: MONGODB_HOST\n    valueFrom:\n      secretKeyRef:\n        name: {{ .Values.mongodbAccess | quote }}\n        key: MONGODB_HOST\n</code></pre> <p>Update project files</p> <ul> <li> <p>Update the <code>StockItem.java</code> file, add an <code>@Id</code> annotation on the <code>id</code> field.  src/main/java/com/ibm/inventory_management/models/StockItem.java<pre><code>package com.ibm.inventory_management.models;\n\nimport org.springframework.data.annotation.Id;\n\nimport java.io.Serializable;\n\npublic class StockItem implements Serializable {\n  private String name;\n  @Id\n  private String id = null;\n  private int stock = 0;\n  private double price = 0.0;\n  private String manufacturer = \"\";\n\n  public StockItem() {\n    super();\n  }\n\n  public StockItem(String id) {\n    this.id = id;\n  }\n\n  public String getName() {\n    return name;\n  }\n\n  public void setName(String name) {\n    this.name = name;\n  }\n\n  public StockItem withName(String name) {\n    this.setName(name);\n    return this;\n  }\n\n  public String getId() {\n    return id;\n  }\n\n  public void setId(String id) {\n    this.id = id;\n  }\n\n  public StockItem withId(String id) {\n    this.setId(id);\n    return this;\n  }\n\n  public int getStock() {\n    return stock;\n  }\n\n  public void setStock(int stock) {\n    this.stock = stock;\n  }\n\n  public StockItem withStock(int stock) {\n    this.setStock(stock);\n    return this;\n  }\n\n  public double getPrice() {\n    return price;\n  }\n\n  public void setPrice(double price) {\n    this.price = price;\n  }\n\n  public StockItem withPrice(double price) {\n    this.setPrice(price);\n    return this;\n  }\n\n  public String getManufacturer() {\n    return manufacturer;\n  }\n\n  public void setManufacturer(String manufacturer) {\n    this.manufacturer = manufacturer;\n  }\n\n  public StockItem withManufacturer(String manufacturer) {\n    this.setManufacturer(manufacturer);\n    return this;\n  }\n}\n</code></pre></p> </li> <li> <p>Create a <code>StockItemRepository.java</code> interface to interact with the database, put it in a <code>repositories</code> directory.  src/main/java/com/ibm/inventory_management/repositories/StockItemRepository.java<pre><code>package com.ibm.inventory_management.repositories;\n\nimport com.ibm.inventory_management.models.StockItem;\nimport org.springframework.data.mongodb.repository.MongoRepository;\nimport org.springframework.stereotype.Repository;\n\nimport java.util.Optional;\n\n@Repository\npublic interface StockItemRepository extends MongoRepository&lt;StockItem, String&gt; {\n    Optional&lt;StockItem&gt; findById(String id);\n}\n</code></pre></p> </li> <li> <p>Update the <code>StockItemApi.java</code> interface to have CRUD operations.  src/main/java/com/ibm/inventory_management/services/StockItemApi.java<pre><code>package com.ibm.inventory_management.services;\n\nimport java.util.List;\n\nimport com.ibm.inventory_management.models.StockItem;\n\npublic interface StockItemApi {\n  List&lt;StockItem&gt; listStockItems() throws Exception;\n\n  void addStockItem(String name, Double price, Integer stock, String manufacturer) throws Exception;\n\n  void updateStockItem(String id, String name, Double price, Integer stock, String manufacturer) throws Exception;\n\n  void deleteStockItem(String id) throws Exception;\n}\n</code></pre></p> </li> <li> <p>Update the <code>StockItemService.java</code> to implement the interface and use the repository.  src/main/java/com/ibm/inventory_management/services/StockItemService.java<pre><code>package com.ibm.inventory_management.services;\n\nimport java.util.List;\n\nimport com.ibm.inventory_management.repositories.StockItemRepository;\nimport org.bson.types.ObjectId;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\n\nimport com.ibm.inventory_management.models.StockItem;\n\n@Service\npublic class StockItemService implements StockItemApi {\n      @Autowired\n      private StockItemRepository stockItemRepository;\n      @Override\n      public List&lt;StockItem&gt; listStockItems() {\n            return stockItemRepository.findAll();\n      }\n\n      @Override\n      public void addStockItem(String name, Double price, Integer stock, String manufacturer) throws Exception {\n            try {\n                  stockItemRepository.save(\n                          new StockItem(ObjectId.get().toString())\n                                  .withName(name)\n                                  .withManufacturer(manufacturer)\n                                  .withStock(stock)\n                                  .withPrice(price)\n                  );\n            } catch (Exception e) {\n                  throw new Exception(\"\",e);\n            }\n      }\n\n      @Override\n      public void updateStockItem(String id, String name, Double price, Integer stock, String manufacturer) throws Exception {\n            try {\n                  StockItem itemToUpdate = stockItemRepository.findById(id).get();\n\n                  itemToUpdate.setName(name !=null ? name : itemToUpdate.getName());\n                  itemToUpdate.setManufacturer(manufacturer != null ? manufacturer : itemToUpdate.getManufacturer());\n                  itemToUpdate.setPrice(price != null ? price : itemToUpdate.getPrice());\n                  itemToUpdate.setStock(stock != null ? stock : itemToUpdate.getStock());\n\n                  stockItemRepository.save(itemToUpdate);\n            } catch (Exception e) {\n                  throw new Exception(\"\",e);\n            }\n      }\n\n      @Override\n      public void deleteStockItem(String id) throws Exception {\n            try {\n                 stockItemRepository.deleteById(id);\n            } catch (Exception e){\n                 throw new Exception(\"\",e);\n            }\n      }\n}\n</code></pre></p> </li> </ul>"},{"location":"labs/inventory-app/inventory-mongodb/#running-the-application-locally","title":"Running the application locally","text":"<ul> <li>Start the application locally   <pre><code>./gradlew build\n./gradlew bootrun\n</code></pre></li> </ul> <p>Tip</p> <p>If you are using MongoDB on OpenShift, you can use the <code>oc port-forward</code> command to access your database instance through <code>localhost</code></p> <ul> <li> <p>Open a browser to <code>http://localhost:9080/swagger-ui.html</code></p> </li> <li> <p>Once the application is up, go the Swagger UI and execute get <code>stock-items</code>.</p> </li> <li> <p>You should be able to see all the data you pushed to the database through ./dataload.sh</p> </li> </ul> <p></p> <p>Prebuilt solution for this can be found here: Inventory Management Service MongoDB solution template</p> <p>Note</p> <p>You will need to setup your own database credentials in the <code>application.yml</code> file.</p>"},{"location":"labs/inventory-app/inventory-service/","title":"Service","text":""},{"location":"labs/inventory-app/inventory-service/#setup","title":"Setup","text":""},{"location":"labs/inventory-app/inventory-service/#create-your-openshift-project-git-repository-and-ci-pipeline","title":"Create your OpenShift project, Git Repository and CI pipeline","text":"<ul> <li> <p>Create a new repository for the service from the Spring Boot Microservice template. Make the cloned repository public.</p> <p>Warning</p> <p>In order to prevent naming collisions if you are running this as part of a workshop, chose the GitHub organization you have been invited to as <code>Owner</code> and name the repository <code>inv-svc-${UNIQUE_SUFFIX}</code>, replacing <code>${UNIQUE_SUFFIX}</code> with your team name or initials.</p> </li> <li> <p>Deploy this application with Tekton:</p> <p>Note</p> <p>You should have the <code>tkn</code>, <code>tkn pac</code> and <code>oc</code> CLIs installed. <code>oc</code> can be installed through the help section of your OpenShift console.</p> <ul> <li>In the OpenShift web console, click on the user ID on the top right, click on Copy login command and get the OpenShift login command, which includes a token.</li> </ul> <p></p> <ul> <li>Click on Display Token, copy the Login with the token. oc login command will log you in. Run the login command in your terminal:</li> </ul> <pre><code>oc login --token=&lt;OCP_TOKEN&gt; --server=&lt;OCP_SERVER&gt;\n</code></pre> <ul> <li>Create a new <code>inventory-${UNIQUE_SUFFIX}-dev</code> project (setting the <code>UNIQUE_SUFFIX</code> environment variables with your team name or initials to have a unique name):</li> </ul> <pre><code>export UNIQUE_SUFFIX=ns # CHANGEME\noc new-project inventory-${UNIQUE_SUFFIX}-dev\n</code></pre> <ul> <li>Create <code>registry-config</code> and <code>ci-config</code> secrets required for your pipeline runs to access your container registry:</li> </ul> <pre><code>cat &lt;&lt;EOF | oc apply -f -\n---\nkind: Secret\napiVersion: v1\nmetadata:\n  name: registry-config\n  namespace: inventory-${UNIQUE_SUFFIX}-dev\nstringData:\n  config.json: '{\"auths\":...}' # CHANGEME\ntype: Opaque\n---\nkind: Secret\napiVersion: v1\nmetadata:\n  name: ci-config\n  namespace: inventory-${UNIQUE_SUFFIX}-dev\nstringData:\n  img-namespace: library # CHANGEME\n  img-server: core.harbor.example.com # CHANGEME\ntype: Opaque\nEOF\n</code></pre> <p>Note</p> <p>If you are doing this lab as part of a workshop secrets have been created for you in the <code>ci-tools</code> namespace, you just need to copy them:</p> <pre><code>oc get secret registry-config -n ci-tools -o yaml | sed \"s/ci-tools/inventory-${UNIQUE_SUFFIX}-dev/g\" | oc apply -f -\noc get secret ci-config -n ci-tools -o yaml | sed \"s/ci-tools/inventory-${UNIQUE_SUFFIX}-dev/g\" | oc apply -f -\n</code></pre> <ul> <li>Clone the repo locally:</li> </ul> <pre><code>git clone https://github.com/cloud-design-patterns-journey/inv-svc-${UNIQUE_SUFFIX}.git\ncd inv-svc-${UNIQUE_SUFFIX}\n</code></pre> <ul> <li>Create the tekton pipeline for the backend service your new project:</li> </ul> <pre><code>oc adm policy add-scc-to-user privileged -z pipeline\ntkn pac create repository\n</code></pre> <p>Note</p> <ul> <li><code>tkn pac create repository</code> assumes you have Pipelines-as-Code already setup on your cluster and Git provider. If you are running this lab as part of a workshop, this has been configured for you, make sure you use the provided GitHub organization when you create yout Git repository from template above.</li> <li><code>oc adm policy add-scc-to-user privileged -z pipeline</code> will make sure that the Tekton pipeline will be able to escalade privileges in your <code>inventory-${UNIQUE_SUFFIX}-dev</code> project/namespace.</li> </ul> <ul> <li>In OpenShift console (Pipelines Section &gt; Pipelines &gt; Repositories), edit the newly created <code>Repository</code> YAML to add cluster specific configuration (e.g. image repository):</li> </ul> <pre><code>...\nspec:\n  params:\n    - name: img-server\n      secret_ref:\n        name: ci-config\n        key: img-server\n    - name: img-namespace\n      secret_ref:\n        name: ci-config\n        key: img-namespace\n...\n</code></pre> </li> </ul>"},{"location":"labs/inventory-app/inventory-service/#create-initial-components","title":"Create initial components","text":""},{"location":"labs/inventory-app/inventory-service/#setup-your-development-environment","title":"Setup your development environment","text":"<p>Navigate to your cloned repository and open it using your favorite text editor or IDE (Visual Studio Code, IntelliJ...).</p> <p>You are now ready to modify the application!</p>"},{"location":"labs/inventory-app/inventory-service/#update-the-template","title":"Update the template","text":"<p>Spring Boot uses annotations to configure the various components that will be injected into and used by the applications. A class with the <code>@SpringBootApplication</code> annotation is the starting point for the rest of the application components to be loaded. Additionally, a <code>@ComponentScan</code> annotation can be added to tell the Spring infrastructure which packages should be scanned for components.</p> <p>We will start by creating the initial application component.</p> <ul> <li>Copy the template app into a new <code>inventory_management</code> app:</li> </ul> <pre><code>mv src/main/java/com/ibm/hello src/main/java/com/ibm/inventory_management\nsed -i -e 's/com.ibm.hello/com.ibm.inventory_management/g' src/main/java/com/ibm/inventory_management/*/*.java\nrm src/main/java/com/ibm/inventory_management/HelloWatsonApplication.java\n</code></pre> <ul> <li>Create a class named <code>Application</code> in the <code>com.ibm.inventory_management.app</code> package and add the <code>@SpringBootApplication</code> and <code>@ComponentScan</code> annotation to the class. The <code>@ComponentScan</code>   annotation should include <code>com.ibm.inventory_management.*</code>, <code>com.ibm.cloud_native_toolkit.*</code>, and <code>com.ibm.health</code> packages:</li> </ul> src/main/java/com/ibm/inventory_management/app/Application.java<pre><code>package com.ibm.inventory_management.app;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.CommandLineRunner;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.boot.builder.SpringApplicationBuilder;\nimport org.springframework.boot.web.servlet.support.SpringBootServletInitializer;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.ComponentScan;\nimport org.springframework.core.env.Environment;\n\n@SpringBootApplication\n@ComponentScan({ \"com.ibm.inventory_management.*\", \"com.ibm.cloud_garage.*\", \"com.ibm.health\" })\npublic class Application extends SpringBootServletInitializer {\n    @Autowired\n    Environment environment;\n\n    public static void main(String[] args) {\n        SpringApplication.run(com.ibm.inventory_management.app.Application.class, args);\n    }\n\n    @Bean\n    public CommandLineRunner commandLineRunner(ApplicationContext ctx) {\n        return args -&gt; {\n            String port = environment.getProperty(\"local.server.port\");\n\n            System.out.println();\n            System.out.println(\"Server started - http://localhost:\" + port + \"/swagger-ui.html\");\n        };\n    }\n\n    @Override\n    protected SpringApplicationBuilder configure(SpringApplicationBuilder application) {\n        return application.sources(Application.class);\n    }\n}\n</code></pre> <ul> <li>Commit and push the changes to Git.</li> </ul> <pre><code>git add .\ngit commit -s -m \"Adds Application and Removes sample app\"\ngit push\n</code></pre> <ul> <li>The CI pipeline should kick off. Once complete, you will be able to test the deployed service by going to the service route (accessible from openshift Console, or by running <code>oc get route</code>).</li> </ul>"},{"location":"labs/inventory-app/inventory-service/#add-stockitem-controller","title":"Add StockItem controller","text":"<p>In Spring Boot, the <code>@RestController</code> annotation tells the framework that the class provides a REST interface. Additional annotations like <code>@GetMapping</code> are used to provide the specific configuration for the REST service.</p> <ul> <li> <p>Start the tests in tdd mode with <code>npm run tdd</code> (or <code>./gradlew test --continuous</code>)</p> </li> <li> <p>Add a StockItemControllerTest.java in <code>com.ibm.inventory_management.controllers</code> under the <code>test</code> folder</p> </li> </ul> src/test/java/com/ibm/inventory_management/controllers/StockItemControllerTest.java<pre><code>package com.ibm.inventory_management.controllers;\n\nimport org.junit.jupiter.api.DisplayName;\n\n@DisplayName(\"StockItemController\")\npublic class StockItemControllerTest {\n}\n</code></pre> <ul> <li>Add the MockMvc infrastructure and create the <code>StockItemController</code></li> </ul> src/test/java/com/ibm/inventory_management/controllers/StockItemControllerTest.java<pre><code>package com.ibm.inventory_management.controllers;\n\nimport static org.mockito.Mockito.spy;\n\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.DisplayName;\nimport org.springframework.test.web.servlet.MockMvc;\nimport org.springframework.test.web.servlet.setup.MockMvcBuilders;\n\n@DisplayName(\"StockItemController\")\npublic class StockItemControllerTest {\nStockItemController controller;\n\nMockMvc mockMvc;\n\n@BeforeEach\npublic void setup() {\n    controller = spy(new StockItemController());\n\n    mockMvc = MockMvcBuilders.standaloneSetup(controller).build();\n  }\n}\n</code></pre> src/main/java/com/ibm/inventory_management/controllers/StockItemController.java<pre><code>package com.ibm.inventory_management.controllers;\n\npublic class StockItemController {\n}\n</code></pre> <ul> <li>Add the tests for the controller behavior and make the corresponding changes to make the tests pass</li> </ul> src/test/java/com/ibm/inventory_management/controllers/StockItemControllerTest.java<pre><code>package com.ibm.inventory_management.controllers;\n\nimport static org.mockito.Mockito.spy;\nimport static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.get;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;\n\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.DisplayName;\nimport org.junit.jupiter.api.Nested;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.test.web.servlet.MockMvc;\nimport org.springframework.test.web.servlet.setup.MockMvcBuilders;\n\n@DisplayName(\"StockItemController\")\npublic class StockItemControllerTest {\n  StockItemController controller;\n\n  MockMvc mockMvc;\n\n  @BeforeEach\n  public void setup() {\n      controller = spy(new StockItemController());\n\n      mockMvc = MockMvcBuilders.standaloneSetup(controller).build();\n  }\n\n  @Nested\n  @DisplayName(\"Given [GET] /stock-items\")\n  public class GivenGetStockItems {\n\n      @Test\n      @DisplayName(\"When called then it should return a 200 status\")\n      public void when_called_should_return_200_status() throws Exception {\n\n          mockMvc.perform(get(\"/stock-items\"))\n                  .andExpect(status().isOk());\n      }\n\n      @Test\n      @DisplayName(\"When called then it should return an empty array\")\n      public void when_called_then_return_an_empty_array() throws Exception {\n\n          mockMvc.perform(get(\"/stock-items\").accept(\"application/json\"))\n                  .andExpect(content().json(\"[]\"));\n      }\n  }\n}\n</code></pre> src/main/java/com/ibm/inventory_management/controllers/StockItemController.java<pre><code>package com.ibm.inventory_management.controllers;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class StockItemController {\n\n  @GetMapping(path = \"/stock-items\", produces = \"application/json\")\n  public List listStockItems() {\n   return new ArrayList();\n  }\n}\n</code></pre> <ul> <li>Start the local server</li> </ul> <pre><code>./gradlew bootRun\n</code></pre> <ul> <li> <p>When the server starts, open a browser to <code>http://localhost:9080/swagger-ui.html</code></p> </li> <li> <p>You should see the swagger-ui window documentation with the stock item entry in the list</p> </li> <li> <p>Commit and push the changes to Git.</p> </li> </ul> <pre><code>git add .\ngit commit -s -m \"Adds StockItemController\"\ngit push\n</code></pre> <ul> <li>The CI pipeline should kick off. Once complete, you will be able to test the deployed service by going to the service route (accessible from openshift Console, or by running <code>oc get route</code>).</li> </ul>"},{"location":"labs/inventory-app/inventory-service/#add-a-service-for-providing-results","title":"Add a service for providing results","text":"<p>An established pattern for REST services in Spring Boot is to keep the REST controller logic simple and focused on translating from REST protocols to Javascript. The business logic for the components should be placed in a component that is given a <code>@Service</code> annotation.</p> <ul> <li>Update the controller test to include returning data from the service</li> </ul> src/test/java/com/ibm/inventory_management/controllers/StockItemControllerTest.java<pre><code>package com.ibm.inventory_management.controllers;\n\nimport static org.mockito.Mockito.mock;\nimport static org.mockito.Mockito.spy;\nimport static org.mockito.Mockito.when;\nimport static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.get;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;\n\nimport java.util.Arrays;\nimport java.util.List;\n\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.DisplayName;\nimport org.junit.jupiter.api.Nested;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.test.web.servlet.MockMvc;\nimport org.springframework.test.web.servlet.setup.MockMvcBuilders;\n\nimport com.ibm.inventory_management.models.StockItem;\nimport com.ibm.inventory_management.services.StockItemApi;\n\n@DisplayName(\"StockItemController\")\npublic class StockItemControllerTest {\n StockItemController controller;\n StockItemApi service;\n\n MockMvc mockMvc;\n\n @BeforeEach\n public void setup() {\n     service = mock(StockItemApi.class);\n\n     controller = spy(new StockItemController(service));\n\n     mockMvc = MockMvcBuilders.standaloneSetup(controller).build();\n }\n\n @Nested\n @DisplayName(\"Given [GET] /stock-items\")\n public class GivenGetStockItems {\n\n     @Test\n     @DisplayName(\"When called then it should return a 200 status\")\n     public void when_called_should_return_200_status() throws Exception {\n\n         mockMvc.perform(get(\"/stock-items\"))\n                 .andExpect(status().isOk());\n     }\n\n     @Test\n     @DisplayName(\"When called then it should return an empty array\")\n     public void when_called_then_return_an_empty_array() throws Exception {\n\n         mockMvc.perform(get(\"/stock-items\").accept(\"application/json\"))\n                 .andExpect(content().json(\"[]\"));\n     }\n\n     @Test\n     @DisplayName(\"When called then it should return the results of the StockItemService\")\n     public void when_called_then_return_the_results_of_the_stockitemservice() throws Exception {\n\n         final List&lt;StockItem&gt; expectedResult = Arrays.asList(new StockItem());\n         when(service.listStockItems()).thenReturn(expectedResult);\n\n         mockMvc.perform(get(\"/stock-items\").accept(\"application/json\"))\n                 .andExpect(content().json(\"[{}]\"));\n     }\n   }\n }\n</code></pre> src/main/java/com/ibm/inventory_management/models/StockItem.java<pre><code>package com.ibm.inventory_management.models;\n\nimport java.io.Serializable;\n\npublic class StockItem implements Serializable {\n  private String name;\n\n  public String getName() {\n     return name;\n  }\n  public void setName(String name) {\n     this.name = name;\n  }\n  public StockItem withName(String name) {\n     this.setName(name);\n     return this;\n  }\n}\n</code></pre> src/main/java/com/ibm/inventory_management/services/StockItemApi.java<pre><code>package com.ibm.inventory_management.services;\n\nimport java.util.List;\n\nimport com.ibm.inventory_management.models.StockItem;\n\npublic interface StockItemApi {\n     List&lt;StockItem&gt; listStockItems();\n}\n</code></pre> src/main/java/com/ibm/inventory_management/controllers/StockItemController.java<pre><code>package com.ibm.inventory_management.controllers;\n\nimport java.util.List;\n\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport com.ibm.inventory_management.models.StockItem;\nimport com.ibm.inventory_management.services.StockItemApi;\n\n@RestController\npublic class StockItemController {\n\n  private final StockItemApi service;\n\n  public StockItemController(StockItemApi service) {\n    this.service = service;\n  }\n\n    @GetMapping(path = \"/stock-items\", produces = \"application/json\")\n  public List&lt;StockItem&gt; listStockItems() {\n    return this.service.listStockItems();\n  }\n}\n</code></pre> <ul> <li> <p>At this points the tests should pass even though we haven't provided an implementation of the service yet since we are   creating a mocking the service in the unit test</p> </li> <li> <p>Update the <code>StockItem</code> model to include the remaining fields</p> </li> </ul> src/main/java/com/ibm/inventory_management/models/StockItem.java<pre><code>package com.ibm.inventory_management.models;\n\nimport java.io.Serializable;\n\npublic class StockItem implements Serializable {\n  private String name;\n  private String id = null;\n  private int stock = 0;\n  private double price = 0.0;\n  private String manufacturer = \"\";\n\n  public StockItem() {\n     super();\n  }\n  public StockItem(String id) {\n     this.id = id;\n  }\n\n  public String getName() {\n      return name;\n  }\n  public void setName(String name) {\n      this.name = name;\n  }\n  public StockItem withName(String name) {\n      this.setName(name);\n      return this;\n  }\n\n  public String getId() {\n      return id;\n  }\n\n  public void setId(String id) {\n      this.id = id;\n  }\n\n  public StockItem withId(String id) {\n      this.setId(id);\n      return this;\n  }\n\n  public int getStock() {\n      return stock;\n  }\n\n  public void setStock(int stock) {\n      this.stock = stock;\n  }\n\n  public StockItem withStock(int stock) {\n      this.setStock(stock);\n      return this;\n  }\n\n  public double getPrice() {\n      return price;\n  }\n\n  public void setPrice(double price) {\n      this.price = price;\n  }\n\n  public StockItem withPrice(double price) {\n      this.setPrice(price);\n      return this;\n  }\n\n  public String getManufacturer() {\n      return manufacturer;\n  }\n\n  public void setManufacturer(String manufacturer) {\n      this.manufacturer = manufacturer;\n  }\n\n  public StockItem withManufacturer(String manufacturer) {\n      this.setManufacturer(manufacturer);\n      return this;\n  }\n}\n</code></pre> <ul> <li>Provide an implementation of the service that just returns a couple of hard-coded data values, for now. Services are   denoted in Spring Boot with the <code>@Service</code> annotation</li> </ul> src/main/java/com/ibm/inventory_management/services/StockItemService.java<pre><code>package com.ibm.inventory_management.services;\n\nimport static java.util.Arrays.asList;\n\nimport java.util.List;\n\nimport org.springframework.context.annotation.Primary;\nimport org.springframework.stereotype.Service;\n\nimport com.ibm.inventory_management.models.StockItem;\n\n@Service\npublic class StockItemService implements StockItemApi {\n  @Override\n  public List&lt;StockItem&gt; listStockItems() {\n      return asList(\n              new StockItem(\"1\")\n                      .withName(\"Item 1\")\n                      .withStock(100)\n                      .withPrice(10.5)\n                      .withManufacturer(\"Sony\"),\n              new StockItem(\"2\")\n                      .withName(\"Item 2\")\n                      .withStock(150)\n                      .withPrice(100.0)\n                      .withManufacturer(\"Insignia\"),\n              new StockItem(\"3\")\n                      .withName(\"Item 3\")\n                      .withStock(10)\n                      .withPrice(1000.0)\n                      .withManufacturer(\"Panasonic\")\n      );\n  }\n}\n</code></pre>"},{"location":"labs/inventory-app/inventory-service/#verify-the-service-locally-and-push-the-changes","title":"Verify the service locally and push the changes","text":"<ul> <li>Start the application</li> </ul> <pre><code>./gradlew bootRun\n</code></pre> <ul> <li> <p>Open a browser to <code>http://localhost:9080/swagger-ui.html</code></p> </li> <li> <p>Run the service by selecting <code>Try it out</code> then <code>Execute</code></p> </li> <li> <p>You should see the data we defined in the service in the previous section</p> </li> <li> <p>Commit and push the changes to git</p> </li> </ul> <pre><code>git add .\ngit commit -s -m \"Adds StockItem service implementation\"\ngit push\n</code></pre> <ul> <li>The CI pipeline should kick off. Once complete, you will be able to test the deployed service by going to the service route (accessible from openshift Console, or by running <code>oc get route</code>).</li> </ul>"},{"location":"labs/inventory-app/inventory-service/#complete-crud-operations","title":"Complete CRUD operations","text":""},{"location":"labs/inventory-app/inventory-service/#add-post-put-and-delete-routes","title":"Add POST, PUT and DELETE routes","text":"<ul> <li>Update the <code>StockItemApi.java</code> interface to support the other CRUD operations   src/main/java/com/ibm/inventory_management/services/StockItemApi.java<pre><code>package com.ibm.inventory_management.services;\n\nimport java.util.List;\n\nimport com.ibm.inventory_management.models.StockItem;\n\npublic interface StockItemApi {\n  List&lt;StockItem&gt; listStockItems();\n\n  void updateStockItem(String id, String name, String manufacturer, double price, int stock);\n\n  void addStockItem(String name, String manufacturer, double price, int stock);\n\n  void deleteStockItem(String id);\n}\n</code></pre></li> <li>Update the <code>StockItemService.java</code> class to implement the methods of the interface   src/main/java/com/ibm/inventory_management/services/StockItemService.java<pre><code>package com.ibm.inventory_management.services;\n\nimport static java.util.Arrays.asList;\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\nimport org.springframework.stereotype.Service;\n\nimport com.ibm.inventory_management.models.StockItem;\n\n@Service\npublic class StockItemService implements StockItemApi {\n    static int id = 0;\n    static List&lt;StockItem&gt; stockItems = new ArrayList&lt;&gt;(asList(\n            new StockItem(++id+\"\")\n                    .withName(\"Item 1\")\n                    .withStock(100)\n                    .withPrice(10.5)\n                    .withManufacturer(\"Sony\"),\n            new StockItem(++id+\"\")\n                    .withName(\"Item 2\")\n                    .withStock(150)\n                    .withPrice(100.5)\n                    .withManufacturer(\"Insignia\"),\n            new StockItem(++id+\"\")\n                    .withName(\"Item 3\")\n                    .withStock(10)\n                    .withPrice(1000.0)\n                    .withManufacturer(\"Panasonic\")\n    ));\n\n    @Override\n    public List&lt;StockItem&gt; listStockItems() {\n      return this.stockItems;\n    }\n\n    @Override\n    public void addStockItem(String name, String manufacturer, double price, int stock) {\n        this.stockItems.add(new StockItem(++id+\"\")\n                .withName(name)\n                .withStock(stock)\n                .withPrice(price)\n                .withManufacturer(manufacturer)\n        );\n    }\n\n    @Override\n    public void updateStockItem(String id, String name, String manufacturer, double price, int stock) {\n       StockItem itemToUpdate = this.stockItems.stream().filter(stockItem -&gt; stockItem.getId().equals(id)).findFirst().orElse(null);\n\n       if(itemToUpdate == null) {\n           System.out.println(\"Item not found\");\n           return;\n       }\n\n       itemToUpdate.setName(name !=null ? name : itemToUpdate.getName());\n       itemToUpdate.setManufacturer(manufacturer != null ? manufacturer : itemToUpdate.getManufacturer());\n       itemToUpdate.setPrice(Double.valueOf(price) != null ? price : itemToUpdate.getPrice());\n       itemToUpdate.setStock(Integer.valueOf(stock) != null ? stock : itemToUpdate.getStock());\n    }\n\n    @Override\n    public void deleteStockItem(String id) {\n        this.stockItems = this.stockItems.stream().filter((stockItem)-&gt; !stockItem.getId().equals(id)).collect(Collectors.toList());\n    }\n}\n</code></pre></li> <li>Update the <code>StockItemController.java</code> class to provide the additional routes   src/main/java/com/ibm/inventory_management/controllers/StockItemController.java<pre><code>package com.ibm.inventory_management.controllers;\n\nimport java.util.List;\n\nimport org.springframework.web.bind.annotation.*;\n\nimport com.ibm.inventory_management.models.StockItem;\nimport com.ibm.inventory_management.services.StockItemApi;\n\n@RestController\npublic class StockItemController {\n\n  private final StockItemApi service;\n\n  public StockItemController(StockItemApi service) {\n    this.service = service;\n  }\n\n  @GetMapping(path = \"/stock-items\", produces = \"application/json\")\n  public List&lt;StockItem&gt; listStockItems() {\n    return this.service.listStockItems();\n  }\n\n  @PostMapping(path = \"/stock-item\")\n  public void addStockItem(@RequestParam String name, @RequestParam String manufacturer, @RequestParam float price, @RequestParam int stock) {\n    this.service.addStockItem(name,manufacturer,price,stock);\n  }\n\n  @PutMapping(path = \"/stock-item/{id}\")\n  public void updateStockItem(@PathVariable(\"id\") String id, @RequestParam String name, @RequestParam String manufacturer, @RequestParam float price, @RequestParam int stock) {\n    this.service.updateStockItem(id,name,manufacturer,price,stock);\n  }\n\n  @DeleteMapping(path = \"/stock-item/{id}\")\n  public void deleteStockItem(@PathVariable(\"id\") String id){\n    this.service.deleteStockItem(id);\n  }\n}\n</code></pre></li> </ul>"},{"location":"labs/inventory-app/inventory-service/#verify-the-changes-and-push-the-new-code","title":"Verify the changes and push the new code","text":"<ul> <li>Start the application</li> </ul> <pre><code>./gradlew bootRun\n</code></pre> <p>You should see new routes on the Swagger UI.   </p> <ul> <li>Commit and push the changes to Git to trigger build pipeline on your OpenShift cluster.</li> </ul> <pre><code>git add .\ngit commit -s -m \"Added CRUD operations\"\ngit push\n</code></pre> <ul> <li>The CI pipeline should kick off. Once complete, you will be able to test the deployed service by going to the service route (accessible from openshift Console, or by running <code>oc get route</code>).</li> </ul>"},{"location":"labs/inventory-app/inventory-ui/","title":"UI","text":""},{"location":"labs/inventory-app/inventory-ui/#develop-and-deploy-the-ui-component-of-the-inventory-application","title":"Develop and deploy the UI component of the inventory application","text":""},{"location":"labs/inventory-app/inventory-ui/#setup","title":"Setup","text":"<p>Note</p> <p>Following this section means you have already deployed and configured the backend and BFF services from the previous steps. Your OpenShift cluster should have the <code>inventory-${UNIQUE_SUFFIX}-dev</code> project (with <code>${UNIQUE_SUFFIX}</code> as your team name or initials), that has been configured with <code>ci-config</code> and <code>registry-config</code> secrets during previous lab.</p>"},{"location":"labs/inventory-app/inventory-ui/#create-your-openshift-project-git-repository-and-ci-pipeline","title":"Create your OpenShift project, Git Repository and CI pipeline","text":"<ul> <li> <p>Create a new repository from the Carbon React template.</p> <p>Warning</p> <p>In order to prevent naming collisions if you are running this as part of a workshop, chose the GitHub organization you have been invited to as <code>Owner</code> and name the repository <code>inv-ui-${UNIQUE_SUFFIX}</code>, replacing <code>${UNIQUE_SUFFIX}</code> with your team name or initials.</p> </li> <li> <p>Deploy this application with Tekton:</p> <p>Note</p> <p>You should have the <code>tkn</code>, <code>tkn pac</code> and <code>oc</code> CLIs installed. <code>oc</code> can be installed through the help section of your OpenShift console.</p> <ul> <li>In the OpenShift web console, click on the user ID on the top right, click on Copy login command and get the OpenShift login command, which includes a token.</li> </ul> <p></p> <ul> <li>Click on Display Token, copy the Login with the token. oc login command will log you in. Run the login command in your terminal:</li> </ul> <pre><code>oc login --token=&lt;OCP_TOKEN&gt; --server=&lt;OCP_SERVER&gt;\n</code></pre> <ul> <li>Move to your <code>inventory-${UNIQUE_SUFFIX}-dev</code> project created in previous lab:</li> </ul> <pre><code>export UNIQUE_SUFFIX=ns # CHANGEME\noc project inventory-${UNIQUE_SUFFIX}-dev\n</code></pre> <ul> <li>Clone the repo locally:</li> </ul> <pre><code>git clone https://github.com/cloud-design-patterns-journey/inv-ui-${UNIQUE_SUFFIX}.git\ncd inv-ui-${UNIQUE_SUFFIX}\n</code></pre> <ul> <li>Create the tekton pipeline for the backend service your new project:</li> </ul> <pre><code>oc adm policy add-scc-to-user privileged -z pipeline\ntkn pac create repository\n</code></pre> <p>Note</p> <ul> <li><code>tkn pac create repository</code> assumes you have Pipelines-as-Code already setup on your cluster and Git provider. If you are running this lab as part of a workshop, this has been configured for you, make sure you use the provided GitHub organization when you create yout Git repository from template above.</li> <li><code>oc adm policy add-scc-to-user privileged -z pipeline</code> will make sure that the Tekton pipeline will be able to escalade privileges in your <code>inventory-${UNIQUE_SUFFIX}-dev</code> project/namespace.</li> </ul> <ul> <li>In OpenShift console (Pipelines Section &gt; Pipelines &gt; Repositories), edit the newly created <code>Repository</code> YAML to add cluster specific configuration (e.g. image repository):</li> </ul> <pre><code>...\nspec:\n  params:\n    - name: img-server\n      secret_ref:\n        name: ci-config\n        key: img-server\n    - name: img-namespace\n      secret_ref:\n        name: ci-config\n        key: img-namespace\n...\n</code></pre> </li> </ul>"},{"location":"labs/inventory-app/inventory-ui/#setup-your-development-environment","title":"Setup your development environment","text":"<p>Clone the project and open it using your favorite text editor or IDE (Visual Studio Code, Atom...).</p> <p>You are now ready to modify the application!</p>"},{"location":"labs/inventory-app/inventory-ui/#create-the-initial-components","title":"Create the initial components","text":"<p>Based on the requirements of this first use case, we will create a <code>StockItemList</code> component to list stock items.</p> <ul> <li> <p>Open a terminal and start the application in development mode to see the initial UI and the changes as we make them:</p> <pre><code>yarn install\nyarn start:dev\n</code></pre> </li> <li> <p>Access the running service. This service runs by default on port <code>3000</code>.</p> </li> <li> <p>Create the <code>StockItemList</code> React component that uses a <code>StructuredList</code> from the Carbon React Components portfolio:     src/content/StockItemList.jsx<pre><code>import React from \"react\";\nimport {\n    StructuredListWrapper, StructuredListHead, StructuredListRow,\n    StructuredListCell, StructuredListBody\n} from '@carbon/react';\n\nconst DEFAULT_ITEMS = [\n    {\n        name: 'Item 1',\n        stock: 10,\n        unitPrice: 51.2,\n        manufacturer: 'Sony'\n    },\n    {\n        name: 'Item 2',\n        stock: 50,\n        unitPrice: 10,\n        manufacturer: 'LG'\n    },\n]\n\nexport default function StockItemList() {\n    const items = DEFAULT_ITEMS;\n\n    return (\n        &lt;div className=\"stock-items-list\"&gt;\n            &lt;h2&gt;Stock Items&lt;/h2&gt;\n            &lt;StructuredListWrapper&gt;\n                &lt;StructuredListHead&gt;\n                    &lt;StructuredListRow head&gt;\n                        &lt;StructuredListCell head&gt;Name&lt;/StructuredListCell&gt;\n                        &lt;StructuredListCell head&gt;Stock&lt;/StructuredListCell&gt;\n                        &lt;StructuredListCell head&gt;Unit Price&lt;/StructuredListCell&gt;\n                        &lt;StructuredListCell head&gt;Manufacturer&lt;/StructuredListCell&gt;\n                    &lt;/StructuredListRow&gt;\n                &lt;/StructuredListHead&gt;\n                &lt;StructuredListBody&gt;\n                    {items.map(item =&gt; (\n                        &lt;StructuredListRow&gt;\n                            &lt;StructuredListCell noWrap&gt;{item.name}&lt;/StructuredListCell&gt;\n                            &lt;StructuredListCell noWrap&gt;{item.stock}&lt;/StructuredListCell&gt;\n                            &lt;StructuredListCell noWrap&gt;{item.unitPrice}&lt;/StructuredListCell&gt;\n                            &lt;StructuredListCell noWrap&gt;{item.manufacturer}&lt;/StructuredListCell&gt;\n                        &lt;/StructuredListRow&gt;\n                    ))}\n                &lt;/StructuredListBody&gt;\n            &lt;/StructuredListWrapper&gt;\n        &lt;/div&gt;\n    );\n}\n</code></pre></p> </li> <li> <p>Now that we have our component to list stock items, let's add it to out app by editing the <code>src/content/UIShell/UIShell.jsx</code> file:</p> <ul> <li>Add our new component to the bottom of the imports section:   src/content/UIShell/UIShell.jsx<pre><code>...\nimport StockItemList from \"../StockItemList\";\n...\n</code></pre></li> <li>Add a menu to our left navigation panel to link to a new <code>/inventory/items</code> route that we'll use to list stock items:   src/content/UIShell/UIShell.jsx<pre><code>...\n&lt;SideNav aria-label=\"Side navigation\" expanded={isSideNavExpanded}&gt;\n    &lt;SideNavItems&gt;\n        &lt;SideNavMenuItem element={Link} to='/'\n            isActive={this.state.activeItem === '/'}\n            onClick={() =&gt; { this.setState({ activeItem: '/' }) }}&gt;\n            Overview\n        &lt;/SideNavMenuItem&gt;\n        &lt;SideNavMenu renderIcon={Fade} title=\"Inventory\" defaultExpanded&gt;\n            &lt;SideNavMenuItem element={Link} to='/inventory/items'\n                isActive={this.state.activeItem === '/inventory/items'}\n                onClick={() =&gt; { this.setState({ activeItem: '/inventory/items' }) }}&gt;\n                Items\n            &lt;/SideNavMenuItem&gt;\n        &lt;/SideNavMenu&gt;\n        &lt;SideNavMenu renderIcon={Fade} title=\"Management\"&gt;\n            &lt;SideNavMenuItem href=\"#\"&gt;\n                Link\n            &lt;/SideNavMenuItem&gt;\n            &lt;SideNavMenuItem href=\"#\"&gt;\n                Link\n            &lt;/SideNavMenuItem&gt;\n            &lt;SideNavMenuItem href=\"#\"&gt;\n                Link\n            &lt;/SideNavMenuItem&gt;\n        &lt;/SideNavMenu&gt;\n        &lt;SideNavMenu\n            renderIcon={Fade}\n            title=\"Docs\"&gt;\n            &lt;SideNavMenuItem href=\"#\"&gt;\n                Link\n            &lt;/SideNavMenuItem&gt;\n            &lt;SideNavMenuItem href=\"#\"&gt;\n                Link\n            &lt;/SideNavMenuItem&gt;\n        &lt;/SideNavMenu&gt;\n    &lt;/SideNavItems&gt;\n&lt;/SideNav&gt;\n...\n</code></pre></li> <li>Add a new route for the <code>/inventory/items</code> route:   src/content/UIShell/UIShell.jsx<pre><code>...\n&lt;Routes&gt;\n    &lt;Route path=\"/\" element={&lt;LandingPage /&gt;} /&gt;\n    &lt;Route path=\"/inventory/items\" element={&lt;StockItemList /&gt;} /&gt;\n    &lt;Route path=\"*\" element={&lt;NotFound /&gt;} /&gt;\n&lt;/Routes&gt;\n...\n</code></pre></li> </ul> </li> <li> <p>Open the application to check that you can now navigate to the Stock Items view:     </p> </li> <li> <p>With the application running in the first terminal, open a second terminal in the repository directory and push the changes we've just made:     <pre><code>git add .\ngit commit -m \"Initial shell components\"\ngit push\n</code></pre></p> </li> <li> <p>CI pipeline should be kicked off, you can test the hosted application once complete.</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-ui/#add-a-service-component-to-get-mock-stock-items","title":"Add a service component to get mock Stock Items","text":"<p>Now that we've created the initial components, we can start to customize the <code>StockItemList</code> to match the data for our application. So far, we've built a UI that displays a hard-coded set of data in a table. Eventually, we want to display dynamic data provided from a database in the table. As a first step towards that goal, we need to separate the UI logic from the logic that retrieves the data. We will do that with a service component. For this first pass the service component will just return mock data.</p> <ul> <li> <p>Create a <code>src/services</code> directory:     <pre><code>mkdir src/services\n</code></pre></p> </li> <li> <p>Create a file named <code>stock-item-mock.service.js</code> in the service directory, implementing the service by copying the data array from <code>StockItemList</code> and returning it in the function. You can add a <code>setTimeout()</code> 1s timeout to simulate loading:     src/services/stock-item-mock.service.js<pre><code>export class StockItemMockService {\n    async listStockItems() {\n        return new Promise(resolve =&gt; {\n            // Wait 1 second before returning data\n            setTimeout(() =&gt; {\n                resolve([\n                    {\n                        id: 1,\n                        name: 'Item 1',\n                        stock: 10,\n                        unitPrice: 51.2,\n                        manufacturer: 'Sony'\n                    },\n                    {\n                        id: 2,\n                        name: 'Item 2',\n                        stock: 50,\n                        unitPrice: 10,\n                        manufacturer: 'LG'\n                    },\n                ]);\n            }, 1000)\n        });\n    }\n}\n</code></pre></p> </li> <li> <p>Update <code>StockItemList.jsx</code> to use the provided service:</p> src/content/StockItemList.jsx<pre><code>import React from 'react';\nimport { useQuery } from '@tanstack/react-query';\nimport {\n    StructuredListWrapper, StructuredListHead, StructuredListRow,\n    StructuredListCell, StructuredListBody, StructuredListSkeleton\n} from '@carbon/react';\n\nexport default function StockItemList(props) {\n    const { isLoading, error, data } = useQuery({\n        queryKey: ['stock-items'],\n        queryFn: props.stockService.listStockItems\n    });\n\n    return (\n        &lt;div className='stock-items-list'&gt;\n            &lt;h2&gt;Stock Items&lt;/h2&gt;\n            {isLoading ?\n                &lt;StructuredListSkeleton /&gt;\n                : error ?\n                    'Error retrieving stock items'\n                    :\n                    &lt;StructuredListWrapper&gt;\n                        &lt;StructuredListHead&gt;\n                            &lt;StructuredListRow head&gt;\n                                &lt;StructuredListCell head&gt;Name&lt;/StructuredListCell&gt;\n                                &lt;StructuredListCell head&gt;Stock&lt;/StructuredListCell&gt;\n                                &lt;StructuredListCell head&gt;Unit Price&lt;/StructuredListCell&gt;\n                                &lt;StructuredListCell head&gt;Manufacturer&lt;/StructuredListCell&gt;\n                            &lt;/StructuredListRow&gt;\n                        &lt;/StructuredListHead&gt;\n                        &lt;StructuredListBody&gt;\n                            {data.map(item =&gt; (\n                                &lt;StructuredListRow key={item.id}&gt;\n                                    &lt;StructuredListCell noWrap&gt;{item.name}&lt;/StructuredListCell&gt;\n                                    &lt;StructuredListCell noWrap&gt;{item.stock}&lt;/StructuredListCell&gt;\n                                    &lt;StructuredListCell noWrap&gt;{item.unitPrice}&lt;/StructuredListCell&gt;\n                                    &lt;StructuredListCell noWrap&gt;{item.manufacturer}&lt;/StructuredListCell&gt;\n                                &lt;/StructuredListRow&gt;\n                            ))}\n                        &lt;/StructuredListBody&gt;\n                    &lt;/StructuredListWrapper&gt;}\n        &lt;/div&gt;\n    );\n}\n</code></pre> </li> <li> <p>Open the app in your browser, if the app isn't started run:</p> <pre><code>yarn start:dev\n</code></pre> </li> <li> <p>Push the changes we've made to the repository:</p> <pre><code>git add .\ngit commit -m \"Adds a mock service\"\ngit push\n</code></pre> </li> <li> <p>CI pipeline should be kicked off, you can test the hosted application once complete.</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-ui/#add-a-service-that-calls-the-bff","title":"Add a service that calls the BFF","text":"<p>Now that we have a mock service that injects data, we can build an implementation of the service that calls our BFF. For the service, we will use <code>axios</code> to make GraphQL calls to the BFF through an HTTP proxy exposed by the server, using <code>http-proxy-middleware</code>.</p> <ul> <li> <p>Install <code>axios</code> and <code>http-proxy-middleware</code>:     <pre><code>yarn add http-proxy-middleware axios\n</code></pre></p> </li> <li> <p>Update the server to proxy BFF requests (configured in <code>API_HOST</code> environment variable) to <code>/api</code> endpoint:     server/server.js<pre><code>const express = require('express');\nconst path = require('path');\nconst { createProxyMiddleware } = require('http-proxy-middleware');\n\nconst app = express();\n\napp.use(express.static(path.join(__dirname, '../build')));\n\napp.use(\n    '/api',\n    createProxyMiddleware({\n        target: process.env.API_HOST ?? 'http://example.com',\n        changeOrigin: true,\n        pathRewrite: {\n            '^/api': '/'\n        },\n    })\n);\n\napp.get('/health', function (req, res) {\n    res.json({ status: 'UP' });\n});\n\napp.get('/*wildcard', function (req, res) {\n    res.sendFile(path.join(__dirname, '../build', 'index.html'));\n});\n\nconst port = process.env.PORT ?? 3000;\napp.listen(port, function () {\n    console.info(`Server listening on http://localhost:${port}`);\n});\n</code></pre></p> </li> <li> <p>Add a <code>src/setupProxy.js</code> file to setup the proxy for local development:     src/setupProxy.js<pre><code>const { createProxyMiddleware } = require('http-proxy-middleware');\n\nmodule.exports = function(app) {\napp.use(\n    '/api',\n    createProxyMiddleware({\n    target: process.env.API_HOST ?? 'http://example.com',\n    changeOrigin: true,\n    pathRewrite: {\n        '^/api': '/'\n    },\n    })\n);\n};\n</code></pre></p> </li> <li> <p>Create a service implementation in the <code>services</code> directory called <code>stock-item.service.js</code> implementing <code>listStockItems()</code> that calls the BFF through the <code>/api</code> proxy:     src/services/stock-item.service.js<pre><code>import axios from \"axios\";\n\nexport class StockItemService {\n    constructor(baseUrl) {\n        this.baseUrl = baseUrl || '/api';\n    }\n\n    async listStockItems() {\n        return axios({\n            url: '/api/graphql',\n            method: \"POST\",\n            data: {\n                query: `\n                {\n                    stockItems {\n                        id\n                        manufacturer\n                        name\n                        picture\n                        stock\n                        unitPrice\n                    }\n                }\n                `\n            }\n        }).then(response =&gt; response.data.data.stockItems);\n    }\n}\n</code></pre></p> </li> <li> <p>Update <code>App.jsx</code> to use the new service instead of the mock service:     src/App.jsx<pre><code>import React, { Component } from 'react';\nimport UIShell from './content/UIShell/UIShell';\nimport './App.scss';\nimport { StockItemService } from \"./services/stock-item.service\";\n\nclass App extends Component {\nconstructor(props) {\n    super(props);\n\n    this.stockService = props.stockService || new StockItemService();\n}\n\nrender() {\n    return (\n    &lt;div className=\"app\"&gt;\n        &lt;UIShell stockService={this.stockService} /&gt;\n    &lt;/div&gt;\n    );\n}\n}\n\nexport default App;\n</code></pre></p> </li> <li> <p>Test the application again by setting <code>API_HOST</code> before running the app:     <pre><code>export API_HOST=http://bff.example.com:3000 # CHANGEME\nyarn start:dev\n</code></pre></p> </li> <li> <p>Open the application to check that your app is now retrieving data from BFF GraphQL endpoint:     </p> </li> <li> <p>Last step before checking out our changes to git is to make sure our Kubernetes/OpenShift deployment will get the <code>API_HOST</code> environment variable configured. To do so, create a secret and patch the deployment to use it as source for environment variables:</p> <pre><code>oc create secret generic inv-ui-${UNIQUE_SUFFIX}-config --from-literal=API_HOST=http://inv-bff-${UNIQUE_SUFFIX}:3000\nkubectl set env --from=secret/inv-ui-${UNIQUE_SUFFIX}-config deployment/inv-ui-${UNIQUE_SUFFIX}\n</code></pre> </li> <li> <p>Push the changes we've made to the repository:     <pre><code>git add .\ngit commit -m \"Updates the StockItemsList view\"\ngit push\n</code></pre></p> </li> <li> <p>CI pipeline should be kicked off, you can test the hosted application once complete.</p> </li> </ul>"},{"location":"labs/inventory-app/inventory-ui/#summary","title":"Summary","text":"<p>Congrats! You have now completed the Micro App Guide demonstrating the Inventory solution.</p>"},{"location":"labs/security/inject-k8s-secrets-vault/","title":"Injecting secrets into Kubernetes pods via Vault Agent","text":"<p>~30 min</p>"},{"location":"labs/security/inject-k8s-secrets-vault/#introduction","title":"Introduction","text":"<p>Deploying applications that act as secret consumers of Vault require the application to:</p> <ul> <li>Authenticate and acquire a client token.</li> <li>Manage the lifecycle of the token.</li> <li>Retrieve secrets from Vault.</li> <li>Manage the leases of any dynamic secrets.</li> </ul> <p>Vault Agent takes responsibility for these tasks and enables your applications to remain unaware of Vault. However, this introduces a new requirement that deployments install and configure Vault Agent alongside the application as a sidecar.</p> <p>The Vault Helm chart enables you to run Vault and the Vault Agent Sidecar Injector service. This injector service leverages the Sidecar container pattern and Kubernetes mutating admission webhook to intercept pods that define specific annotations and inject a Vault Agent container to manage these secrets.</p> <p>This is beneficial because:</p> <ul> <li>Applications remain Vault unaware as the secrets are stored on the file-system in their container.</li> <li>Existing deployments require no change; as annotations can be patched.</li> <li>Access to secrets can be enforced via Kubernetes service accounts and namespaces</li> </ul> <p>In this tutorial, you setup Vault and this injector service with the Vault Helm chart. Then you will deploy several applications to demonstrate how this new injector service retrieves and writes these secrets for the applications to use.</p>"},{"location":"labs/security/inject-k8s-secrets-vault/#content","title":"Content","text":"<ul> <li>Injecting secrets into Kubernetes pods via Vault Agent</li> <li>Introduction</li> <li>Content</li> <li>Prerequisites<ul> <li>Install kubectl and helm CLIs</li> </ul> </li> <li>Step 1: Get lab resources</li> <li>Step 2: Installing HashiCorp Vault</li> <li>Step 3: Setting up Vault for secret injection</li> <li>Step 4: Injecting secrets into an app</li> <li>Step 5: Understanding scopes</li> <li>Conclusion</li> </ul>"},{"location":"labs/security/inject-k8s-secrets-vault/#prerequisites","title":"Prerequisites","text":"<p>This tutorial requires:</p> <ul> <li>Docker</li> <li>Kubernetes command-line interface (CLI)<ul> <li>Note: if running on OpenShift, <code>oc</code> CLI can be used, it can be installed through the help section of your OpenShift console.</li> </ul> </li> <li>Helm CLI</li> <li>Kubernetes/OpenShift cluster accessible.<ul> <li>Note: you can run this lab locally using Minikube.</li> </ul> </li> </ul>"},{"location":"labs/security/inject-k8s-secrets-vault/#install-kubectl-and-helm-clis","title":"Install kubectl and helm CLIs","text":"<p>Install <code>kubectl</code> with Homebrew (Linux/Macos).</p> <pre><code>brew install kubernetes-cli\n</code></pre> <p>Install <code>helm</code> with Homebrew.</p> <pre><code>brew install helm\n</code></pre>"},{"location":"labs/security/inject-k8s-secrets-vault/#step-1-get-lab-resources","title":"Step 1: Get lab resources","text":"<ol> <li> <p>Retrieve the web application and additional configuration by cloning the hashicorp-education/learn-vault-kubernetes-sidecar repository from GitHub.</p> <pre><code>$ git clone https://github.com/hashicorp-education/learn-vault-kubernetes-sidecar.git\n</code></pre> </li> <li> <p>Move into the clones repository.</p> <pre><code>$ cd learn-vault-kubernetes-sidecar\n</code></pre> <p>This tutorial assumes that the following commands are executed in this directory.</p> </li> </ol>"},{"location":"labs/security/inject-k8s-secrets-vault/#step-2-installing-hashicorp-vault","title":"Step 2: Installing HashiCorp Vault","text":"<p>The recommended way to run Vault on Kubernetes is via the Helm chart. Helm is a package manager that installs and configures all the necessary components to run Vault in several different modes. A Helm chart includes templates that enable conditional and parameterized execution. These parameters can be set through command-line arguments or defined in YAML.</p> <ol> <li> <p>Add the HashiCorp Helm repository.</p> <pre><code>$ helm repo add hashicorp https://helm.releases.hashicorp.com\n\"hashicorp\" has been added to your repositories\n</code></pre> </li> <li> <p>Update all the repositories to ensure <code>helm</code> is aware of the latest versions.</p> <pre><code>$ helm repo update\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the \"hashicorp\" chart repository\nUpdate Complete. \u2388Happy Helming!\u2388\n</code></pre> </li> <li> <p>Optional: if running on OpenShift, create a <code>vault-ocp.values.yaml</code> file with required configuration for OpenShift (security context constraints):</p> <pre><code>cat &lt;&lt;EOF &gt; vault-ocp.values.yaml\nglobal:\n   openshift: true\n\ninjector:\n   image:\n      repository: \"registry.connect.redhat.com/hashicorp/vault-k8s\"\n      tag: \"1.4.1-ubi\"\n\nagentImage:\n   repository: \"registry.connect.redhat.com/hashicorp/vault\"\n   tag: \"1.16.1-ubi\"\n\nserver:\n   image:\n      repository: \"registry.connect.redhat.com/hashicorp/vault\"\n      tag: \"1.16.1-ubi\"\n\nreadinessProbe:\n   path: \"/v1/sys/health?uninitcode=204\"\nEOF\n</code></pre> </li> <li> <p>Create a new <code>lab-security</code> namespace:     <pre><code>$ kubectl create namespace lab-security\n$ kubectl config set-context --current --namespace lab-security\n</code></pre></p> </li> <li> <p>Install the latest version of the Vault server running in development mode. If running on OpenShift add <code>-f vault-ocp.values.yaml</code> to use additional configuration:</p> <pre><code>$ helm install vault hashicorp/vault --set \"server.dev.enabled=true\" [-f vault-ocp.values.yaml]\nNAME: vault\n## ...\n</code></pre> <p>The Vault pod and Vault Agent Injector pod are deployed in the <code>lab-security</code> namespace.</p> </li> <li> <p>Display all the pods in the <code>lab-security</code> namespace.</p> <pre><code>$ kubectl get pods\nNAME                                    READY   STATUS    RESTARTS   AGE\nvault-0                                 1/1     Running   0          80s\nvault-agent-injector-5945fb98b5-tpglz   1/1     Running   0          80s\n</code></pre> <p>The <code>vault-0</code> pod runs a Vault server in development mode. The <code>vault-agent-injector</code> pod performs the injection based on the annotations present or patched on a deployment.</p> <p>Development mode</p> <p>Running a Vault server in development is automatically initialized and unsealed. This is ideal in a learning environment but NOT recommended for a production environment.</p> <p>Wait until the <code>vault-0</code> pod and <code>vault-agent-injector</code> pod are running and ready (<code>1/1</code>).</p> </li> </ol>"},{"location":"labs/security/inject-k8s-secrets-vault/#step-3-setting-up-vault-for-secret-injection","title":"Step 3: Setting up Vault for secret injection","text":"<p>The applications that you deploy in the Inject secrets into the pod section expect Vault to store a username and password stored at the path <code>internal/database/config</code>. To create this secret requires that a key-value secret engine is enabled and a username and password is put at the specified path.</p> <ol> <li> <p>Start an interactive shell session on the <code>vault-0</code> pod.</p> <pre><code>$ kubectl config set-context --current --namespace lab-security\n$ kubectl exec -it vault-0 -- /bin/sh\n/ $\n</code></pre> <p>Your system prompt is replaced with a new prompt <code>/ $</code>. Commands issued at this prompt are executed on the <code>vault-0</code> container.</p> </li> <li> <p>If not already enabled, enable kv-v2 secrets at the path <code>internal</code> (expect an error if already enabled).</p> <pre><code>$ vault secrets enable -path=internal kv-v2\nSuccess! Enabled the kv-v2 secrets engine at: internal/\n</code></pre> <p>Learn more</p> <p>This tutorial focuses on Vault's integration with Kubernetes and not interacting the key-value secrets engine. For more information refer to the Static Secrets: Key/Value Secret tutorial.</p> </li> <li> <p>Create a secret at path <code>internal/database/config-${INITIALS}</code> with a <code>username</code> and <code>password</code>.</p> <pre><code>$ export INITIALS=ns # CHANGEME\n$ vault kv put internal/database/config-${INITIALS} username=\"db-readonly-username\" password=\"db-secret-password\"\nKey              Value\n---              -----\ncreated_time     2020-03-25T19:03:57.127711644Z\ndeletion_time    n/a\ndestroyed        false\nversion          1\n</code></pre> </li> <li> <p>Verify that the secret is defined at the path <code>internal/database/config-${INITIALS}</code>.</p> <pre><code>$ vault kv get internal/database/config-${INITIALS}\n====== Metadata ======\nKey              Value\n---              -----\ncreated_time     2020-03-25T19:03:57.127711644Z\ndeletion_time    n/a\ndestroyed        false\nversion          1\n\n====== Data ======\nKey         Value\n---         -----\npassword    db-secret-password\nusername    db-readonly-username\n</code></pre> <p>The secret is ready for the application.</p> </li> </ol> <p>Vault provides a Kubernetes authentication method that enables clients to authenticate with a Kubernetes Service Account Token. This token is provided to each pod when it is created.</p> <ol> <li> <p>If not enabled already, enable the Kubernetes authentication method (expect an error if already enabled).</p> <pre><code>$ vault auth enable kubernetes\nSuccess! Enabled kubernetes auth method at: kubernetes/\n</code></pre> <p>Vault accepts a service token from any client in the Kubernetes cluster. During authentication, Vault verifies that the service account token is valid by querying a token review Kubernetes endpoint.</p> </li> <li> <p>Configure the Kubernetes authentication method to use the location of the Kubernetes API.</p> <p>Note</p> <p>For the best compatibility with recent Kubernetes versions, ensure you are using Vault v1.13.3 or greater.</p> <pre><code>$ JWT=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)\n$ KUBERNETES_HOST=https://${KUBERNETES_PORT_443_TCP_ADDR}:443\n$ vault write --tls-skip-verify auth/kubernetes/config \\\ntoken_reviewer_jwt=$JWT kubernetes_host=$KUBERNETES_HOST \\\nkubernetes_ca_cert=@/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n</code></pre> <p>Successful output from the command resembles this example:</p> <pre><code>Success! Data written to: auth/kubernetes/config\n</code></pre> <p>The environment variable <code>KUBERNETES_PORT_443_TCP_ADDR</code> is defined and references the internal network address of the Kubernetes host.</p> <p>For a client to read the secret data defined at <code>internal/database/config-${INITIALS}</code>, requires that the read capability be granted for the path <code>internal/data/database/config-${INITIALS}</code>. This is an example of a policy. A policy defines a set of capabilities.</p> </li> <li> <p>Write out the policy named <code>internal-app-${INITIALS}</code> that enables the <code>read</code> capability for secrets at path <code>internal/data/database/config-${INITIALS}</code>.</p> <pre><code>$ vault policy write internal-app-${INITIALS} - &lt;&lt;EOF\npath \"internal/data/database/config-${INITIALS}\" {\n   capabilities = [\"read\"]\n}\nEOF\n</code></pre> </li> <li> <p>Create a Kubernetes authentication role named <code>internal-app-${INITIALS}</code>.</p> <pre><code>$ vault write auth/kubernetes/role/internal-app-${INITIALS} \\\n        bound_service_account_names=internal-app-${INITIALS} \\\n        bound_service_account_namespaces=lab-security-${INITIALS} \\\n        policies=internal-app-${INITIALS} \\\n        ttl=24h\n</code></pre> <p>Successful output from the command resembles this example:</p> <pre><code>Success! Data written to: auth/kubernetes/role/internal-app-${INITIALS}\n</code></pre> <p>The role connects the Kubernetes service account, <code>internal-app-${INITIALS}</code>, and namespace, <code>lab-security-${INITIALS}</code>, with the Vault policy, <code>internal-app-${INITIALS}</code>. The tokens returned after authentication are valid for 24 hours.</p> </li> <li> <p>Lastly, exit the <code>vault-0</code> pod.</p> </li> </ol>"},{"location":"labs/security/inject-k8s-secrets-vault/#step-4-injecting-secrets-into-an-app","title":"Step 4: Injecting secrets into an app","text":"<p>The Vault Kubernetes authentication role defined a Kubernetes service account named <code>internal-app-${INITIALS}</code>.</p> <p>A service account provides an identity for processes that run in a Pod. With this identity we will be able to run the application within the cluster.</p> <ol> <li> <p>Create a Kubernetes service account named <code>internal-app-${INITIALS}</code> in a new <code>lab-security-${INITIALS}</code> namespace.</p> <pre><code>$ export INITIALS=ns # CHANGEME\n$ kubectl create namespace lab-security-${INITIALS}\n$ kubectl config set-context --current --namespace lab-security-${INITIALS}\n$ kubectl create sa internal-app-${INITIALS}\n</code></pre> </li> <li> <p>Get all the service accounts in the lab-security-${INITIALS} namespace. Verify that the service account has been created.</p> <pre><code>$ kubectl get serviceaccounts\nNAME                   SECRETS   AGE\nlab-security-ns        1         52m\ninternal-app-ns        1         13s\nvault                  1         43m\nvault-agent-injector   1         43m\n</code></pre> <p>The name of the service account here aligns with the name assigned to the <code>bound_service_account_names</code> field when the <code>internal-app-${INITIALS}</code> role was created.</p> </li> </ol> <p>You have created a sample application, published it to DockerHub, and created a Kubernetes deployment that launches this application.</p> <ol> <li> <p>Display the deployment for the <code>orgchart</code> application.</p> <pre><code>$ cat deployment-orgchart.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n   name: orgchart\n   labels:\n      app: orgchart\nspec:\n   selector:\n      matchLabels:\n      app: orgchart\n   replicas: 1\n   template:\n      metadata:\n      annotations:\n      labels:\n         app: orgchart\n      spec:\n      serviceAccountName: internal-app\n      containers:\n         - name: orgchart\n            image: jweissig/app:0.0.1\n</code></pre> <p>The name of this deployment is <code>orgchart</code>. The <code>spec.template.spec.serviceAccountName</code> defines the service account <code>internal-app</code> to run this container.</p> </li> <li> <p>Apply the deployment defined in <code>deployment-orgchart.yaml</code>.</p> <pre><code>$ cat deployment-orgchart.yaml | sed s/internal-app/internal-app-${INITIALS}/g | kubectl apply -f -\ndeployment.apps/orgchart created\n</code></pre> </li> <li> <p>Get all the pods in the <code>lab-security-${INITIALS}</code> namespace and note down the name of the pod with a name prefixed with \"orgchart-\".</p> <pre><code>$ kubectl get pods\nNAME                                    READY   STATUS    RESTARTS   AGE\norgchart-69697d9598-l878s               1/1     Running   0          18s\n</code></pre> <p>The orgchart pod is displayed here as the pod prefixed with <code>orgchart</code>.</p> <p>Additional waiting</p> <p>The deployment of the pod requires the retrieval of the application container from Docker Hub. This displays the STATUS of <code>ContainerCreating</code>. The pod reports that it is not ready (<code>0/1</code>).</p> <p>The Vault-Agent injector looks for deployments that define specific annotations. None of these annotations exist in the current deployment. This means that no secrets are present on the <code>orgchart</code> container in the <code>orgchart</code> pod.</p> <p>Note</p> <p>Consider removing the rest of this section - the user should not purposely fail...</p> </li> <li> <p>Verify that no secrets are written to the <code>orgchart</code> container in the <code>orgchart</code> pod.</p> <pre><code>$ kubectl exec \\\n      $(kubectl get pod -l app=orgchart -o jsonpath=\"{.items[0].metadata.name}\") \\\n      --container orgchart -- ls /vault/secrets\n</code></pre> <p>The output displays that there is no such file or directory named <code>/vault/secrets</code>:</p> <pre><code>ls: /vault/secrets: No such file or directory\ncommand terminated with exit code 1\n</code></pre> </li> </ol> <p>The deployment is running the pod with the <code>internal-app</code> Kubernetes service account in the <code>lab-security-${INITIALS}</code> namespace. The Vault Agent Injector only modifies a deployment if it contains a specific set of annotations. An existing deployment may have its definition patched to include the necessary annotations.</p> <ol> <li> <p>Display the deployment patch <code>patch-inject-secrets.yaml</code>.</p> <pre><code>$ cat patch-inject-secrets.yaml\n</code></pre> <p>patch-inject-secrets.yaml</p> <pre><code>spec:\n   template:\n      metadata:\n      annotations:\n         vault.hashicorp.com/agent-inject: 'true'\n         vault.hashicorp.com/role: 'internal-app'\n         vault.hashicorp.com/agent-inject-secret-database-config.txt: 'internal/data/database/config'\n</code></pre> <p>These annotations define a partial structure of the deployment schema and are prefixed with <code>vault.hashicorp.com</code>.</p> <ul> <li><code>agent-inject</code> enables the Vault Agent Injector service</li> <li><code>role</code> is the Vault Kubernetes authentication role</li> <li><code>agent-inject-secret-FILEPATH</code> prefixes the path of the file, <code>database-config.txt</code> written to the <code>/vault/secrets</code> directory. The value is the path to the secret defined in Vault.</li> <li> <p>Patch the <code>orgchart</code> deployment defined in <code>patch-inject-secrets.yaml</code>.</p> <p>$ kubectl patch deployment orgchart --patch \\     \"$(cat patch-inject-secrets.yaml  | sed s/internal-app/internal-app-${INITIALS}/g | sed s#database/config#database/config-${INITIALS}#g)\" deployment.apps/orgchart patched</p> </li> </ul> <p>A new <code>orgchart</code> pod starts alongside the existing pod. When it is ready the original terminates and removes itself from the list of active pods.</p> </li> <li> <p>Get all the pods in the <code>lab-security-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl get pods\nNAME                                    READY   STATUS     RESTARTS   AGE\norgchart-599cb74d9c-s8hhm               0/2     Init:0/1   0          23s\n</code></pre> <p>Wait until the re-deployed <code>orgchart</code> pod reports that it is <code>Running</code> and ready (<code>2/2</code>).</p> <p>This new pod now launches two containers. The application container, named <code>orgchart</code>, and the Vault Agent container, named <code>vault-agent</code>.</p> </li> <li> <p>Display the logs of the <code>vault-agent</code> container in the new <code>orgchart</code> pod.</p> <pre><code>$ kubectl logs \\\n      $(kubectl get pod -l app=orgchart -o jsonpath=\"{.items[0].metadata.name}\") \\\n      --container vault-agent\n</code></pre> <p>Vault Agent manages the token lifecycle and the secret retrieval. The secret is rendered in the <code>orgchart</code> container at the path <code>/vault/secrets/database-config.txt</code>.</p> </li> <li> <p>Display the secret written to the <code>orgchart</code> container.</p> <pre><code>$ kubectl exec \\\n      $(kubectl get pod -l app=orgchart -o jsonpath=\"{.items[0].metadata.name}\") \\\n      --container orgchart -- cat /vault/secrets/database-config.txt\n</code></pre> <p>The unformatted secret data is present on the container:</p> <pre><code>data: map[password:db-secret-password username:db-readonly-user]\nmetadata: map[created_time:2019-12-20T18:17:50.930264759Z deletion_time: destroyed:false version:2]\n</code></pre> </li> </ol> <p>The structure of the injected secrets may need to be structured in a way for an application to use. Before writing the secrets to the file system a template can structure the data. To apply this template a new set of annotations need to be applied.</p> <ol> <li> <p>Display the annotations file that contains a template definition.</p> <pre><code>$ cat patch-inject-secrets-as-template.yaml\n</code></pre> <p>patch-inject-secrets-as-template.yaml</p> <pre><code>spec:\n   template:\n      metadata:\n      annotations:\n         vault.hashicorp.com/agent-inject: 'true'\n         vault.hashicorp.com/agent-inject-status: 'update'\n         vault.hashicorp.com/role: 'internal-app'\n         vault.hashicorp.com/agent-inject-secret-database-config.txt: 'internal/data/database/config'\n         vault.hashicorp.com/agent-inject-template-database-config.txt: |\n            {{- with secret \"internal/data/database/config\" -}}\n            postgresql://{{ .Data.data.username }}:{{ .Data.data.password }}@postgres:5432/wizard\n            {{- end -}}\n</code></pre> <p>This patch contains two new annotations:</p> <ul> <li><code>agent-inject-status</code> set to <code>update</code> informs the injector reinject these values.</li> <li><code>agent-inject-template-FILEPATH</code> prefixes the file path. The value defines the Vault Agent template to apply to the secret's data.</li> </ul> <p>The template formats the username and password as a PostgreSQL connection string.</p> </li> <li> <p>Apply the updated annotations.</p> <pre><code>$ kubectl patch deployment orgchart --patch \\\n    \"$(cat patch-inject-secrets-as-template.yaml | sed s/internal-app/internal-app-${INITIALS}/g | sed s#database/config#database/config-${INITIALS}#g)\"\ndeployment.apps/exampleapp patched\n</code></pre> </li> <li> <p>Get all the pods in the <code>lab-security-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl get pods\nNAME                                    READY   STATUS    RESTARTS   AGE\norgchart-554db4579d-w6565               2/2     Running   0          16s\n</code></pre> <p>Wait until the re-deployed <code>orgchart</code> pod reports that it is <code>Running</code> and ready (<code>2/2</code>).</p> </li> <li> <p>Finally, display the secret written to the <code>orgchart</code> container in the <code>orgchart</code> pod.</p> <pre><code>$ kubectl exec \\\n      $(kubectl get pod -l app=orgchart -o jsonpath=\"{.items[0].metadata.name}\") \\\n      -c orgchart -- cat /vault/secrets/database-config.txt\n</code></pre> <p>The secrets are rendered in a PostgreSQL connection string is present on the container:</p> <pre><code>postgresql://db-readonly-user:db-secret-password@postgres:5432/wizard\n</code></pre> </li> </ol> <p>The annotations may patch these secrets into any deployment. Pods require that the annotations be included in their initial definition.</p> <ol> <li> <p>Display the pod definition for the <code>payroll</code> application.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: payroll\nlabels:\n   app: payroll\nannotations:\n   vault.hashicorp.com/agent-inject: 'true'\n   vault.hashicorp.com/role: 'internal-app'\n   vault.hashicorp.com/agent-inject-secret-database-config.txt: 'internal/data/database/config'\n   vault.hashicorp.com/agent-inject-template-database-config.txt: |\n      {{- with secret \"internal/data/database/config\" -}}\n      postgresql://{{ .Data.data.username }}:{{ .Data.data.password }}@postgres:5432/wizard\n      {{- end -}}\nspec:\nserviceAccountName: internal-app\ncontainers:\n   - name: payroll\n      image: jweissig/app:0.0.1\n</code></pre> </li> <li> <p>Apply the pod defined in <code>pod-payroll.yaml</code>.</p> <pre><code>$ cat pod-payroll.yaml | sed s/internal-app/internal-app-${INITIALS}/g | sed s#database/config#database/config-${INITIALS}#g | kubectl apply -f -\npod/payroll created\n</code></pre> </li> <li> <p>Get all the pods in the <code>lab-security-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl get pods\nNAME                                    READY   STATUS    RESTARTS   AGE\norgchart-554db4579d-w6565               2/2     Running   0          29m\npayroll                                 2/2     Running   0          12s\n</code></pre> <p>Wait until the <code>payroll</code> pod reports that it is <code>Running</code> and ready (<code>2/2</code>).</p> </li> <li> <p>Display the secret written to the <code>payroll</code> container in the <code>payroll</code> pod.</p> <pre><code>$ kubectl exec \\\n      payroll \\\n      --container payroll -- cat /vault/secrets/database-config.txt\n</code></pre> <p>The secrets are rendered in a PostgreSQL connection string is present on the container:</p> <pre><code>postgresql://db-readonly-user:db-secret-password@postgres:5432/wizard\n</code></pre> </li> </ol>"},{"location":"labs/security/inject-k8s-secrets-vault/#step-5-understanding-scopes","title":"Step 5: Understanding scopes","text":"<p>Pods run with a Kubernetes service account other than the ones defined in the Vault Kubernetes authentication role are NOT able to access the secrets defined at that path.</p> <ol> <li> <p>Display the deployment and service account for the <code>website</code> application.</p> <pre><code>$ cat deployment-website.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: website\nlabels:\n   app: website\nspec:\nselector:\n   matchLabels:\n      app: website\nreplicas: 1\ntemplate:\n   metadata:\n      annotations:\n      vault.hashicorp.com/agent-inject: 'true'\n      vault.hashicorp.com/role: 'internal-app'\n      vault.hashicorp.com/agent-inject-secret-database-config.txt: 'internal/data/database/config'\n      vault.hashicorp.com/agent-inject-template-database-config.txt: |\n         {{- with secret \"internal/data/database/config\" -}}\n         postgresql://{{ .Data.data.username }}:{{ .Data.data.password }}@postgres:5432/wizard\n         {{- end -}}\n      labels:\n      app: website\n   spec:\n      # This service account does not have permission to request the secrets.\n      serviceAccountName: website\n      containers:\n      - name: website\n         image: jweissig/app:0.0.1\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\nname: website\n</code></pre> </li> <li> <p>Apply the deployment and service account defined in <code>deployment-website.yaml</code>.</p> <pre><code>$ kubectl apply --filename deployment-website.yaml\ndeployment.apps/website created\nserviceaccount/website created\n</code></pre> </li> <li> <p>Get all the pods in the <code>lab-security-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl get pods\nNAME                                    READY   STATUS     RESTARTS   AGE\norgchart-554db4579d-w6565               2/2     Running    0          29m\npayroll                                 2/2     Running    0          12s\nwebsite-7fc8b69645-527rf                0/2     Init:0/1   0          76s\n</code></pre> <p>The <code>website</code> deployment creates a pod but it is NEVER ready.</p> </li> <li> <p>Display the logs of the <code>vault-agent-init</code> container in the <code>website</code> pod.</p> <pre><code>$ kubectl logs \\\n      $(kubectl get pod -l app=website -o jsonpath=\"{.items[0].metadata.name}\") \\\n      --container vault-agent-init\n</code></pre> <p>The initialization process failed because the service account name is not authorized:</p> <pre><code>...\n[INFO]  auth.handler: authenticating\n[ERROR] auth.handler: error authenticating: error=\"Error making API request.\n\nURL: PUT http://vault.lab-security-ns.svc:8200/v1/auth/kubernetes/login\nCode: 500. Errors:\n\n* service account name not authorized\" backoff=1.562132589\n</code></pre> <p>The service account, <code>external-app</code> is not assigned to any Vault Kubernetes authentication role. This failure to authenticate causes the deployment to fail initialization.</p> </li> <li> <p>Display the deployment patch <code>patch-website.yaml</code>.</p> <pre><code>spec:\n   template:\n      spec:\n      serviceAccountName: internal-app\n</code></pre> <p>The patch modifies the deployment definition to use the service account <code>internal-app</code>. This Kubernetes service account is authorized by the Vault Kubernetes authentication role.</p> </li> <li> <p>Patch the <code>website</code> deployment defined in <code>patch-website.yaml</code>.</p> <pre><code>$ kubectl patch deployment website --patch \\\n    \"$(cat patch-website.yaml | sed s/internal-app/internal-app-${INITIALS}/g | sed s#database/config#database/config-${INITIALS}#g)\"\n</code></pre> </li> <li> <p>Get all the pods in the <code>lab-security-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl get pods\nNAME                                    READY   STATUS     RESTARTS   AGE\norgchart-554db4579d-w6565               2/2     Running    0          29m\npayroll                                 2/2     Running    0          12s\nwebsite-788d689b87-tll2r                2/2     Running    0          27s\n</code></pre> <p>Wait until the <code>website</code> pod reports that it is <code>Running</code> and ready (<code>2/2</code>).</p> </li> <li> <p>Finally, display the secret written to the <code>website</code> container in the <code>website</code> pod.</p> <pre><code>$ kubectl exec \\\n      $(kubectl get pod -l app=website -o jsonpath=\"{.items[0].metadata.name}\") \\\n      --container website -- cat /vault/secrets/database-config.txt\n</code></pre> <p>The secrets are rendered in a PostgreSQL connection string is present on the container:</p> <pre><code>postgresql://db-readonly-user:db-secret-password@postgres:5432/wizard\n</code></pre> <p>Alternatively, you can define a new Vault Kubernetes role, that enables the original service account access, and patch the deployment.</p> </li> </ol> <p>Pods run in a namespace other than the ones defined in the Vault Kubernetes authentication role are NOT able to access the secrets defined at that path.</p> <ol> <li> <p>Create the <code>lab-security-offsite-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl create namespace lab-security-offsite-${INITIALS}\nnamespace/lab-security-offsite-ns created\n</code></pre> </li> <li> <p>Set the current context to the <code>lab-security-offsite-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl config set-context --current --namespace lab-security-offsite-${INITIALS}\nContext \"...\" modified.\n</code></pre> </li> <li> <p>Create a Kubernetes service account named <code>internal-app-${INITIALS}</code> in the <code>lab-security-offsite-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl create sa internal-app-${INITIALS}\nserviceaccount/internal-app-${INITIALS} created\n</code></pre> </li> <li> <p>Display the deployment for the <code>issues</code> application.</p> <pre><code>$ cat deployment-issues.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: issues\nlabels:\n   app: issues\nspec:\nselector:\n   matchLabels:\n      app: issues\nreplicas: 1\ntemplate:\n   metadata:\n      annotations:\n      vault.hashicorp.com/agent-inject: 'true'\n      vault.hashicorp.com/role: 'internal-app'\n      vault.hashicorp.com/agent-inject-secret-database-config.txt: 'internal/data/database/config'\n      vault.hashicorp.com/agent-inject-template-database-config.txt: |\n         {{- with secret \"internal/data/database/config\" -}}\n         postgresql://{{ .Data.data.username }}:{{ .Data.data.password }}@postgres:5432/wizard\n         {{- end -}}\n      labels:\n      app: issues\n   spec:\n      serviceAccountName: internal-app\n      containers:\n      - name: issues\n         image: jweissig/app:0.0.1\n</code></pre> </li> <li> <p>Apply the deployment defined in <code>deployment-issues.yaml</code>.</p> <pre><code>$ cat deployment-issues.yaml | \\\n    sed s/internal-app/internal-app-${INITIALS}/g | \\\n    sed s#database/config#database/config-${INITIALS}#g | \\\n    kubectl apply -f -\ndeployment.apps/issues created\n</code></pre> </li> <li> <p>Get all the pods in the <code>lab-security-offsite-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl get pods\nNAME                      READY   STATUS     RESTARTS   AGE\nissues-79d8bf7cdf-dkdlq   0/2     Init:0/1   0          3s\n</code></pre> <p>Current context</p> <p>The same command is issued but the results are different because you are now in a different namespace.</p> <p>The <code>issues</code> deployment creates a pod but it is NEVER ready.</p> </li> <li> <p>Display the logs of the <code>vault-agent-init</code> container in the <code>issues</code> pod.</p> <pre><code>$ kubectl logs \\\n   $(kubectl get pod -l app=issues -o jsonpath=\"{.items[0].metadata.name}\") \\\n   --container vault-agent-init\n</code></pre> <p>The initialization process fails because the namespace is not authorized:</p> <pre><code>...\n[INFO]  auth.handler: authenticating\n[ERROR] auth.handler: error authenticating: error=\"Error making API request.\n\nURL: PUT http://vault.lab-security-${INITIALS}.svc:8200/v1/auth/kubernetes/login\nCode: 500. Errors:\n\n* namespace not authorized\" backoff=1.9882590740000001\n</code></pre> <p>The namespace, <code>lab-security-offsite-${INITIALS}</code> is not assigned to any Vault Kubernetes authentication role. This failure to authenticate causes the deployment to fail initialization.</p> </li> <li> <p>Start an interactive shell session on the <code>vault-0</code> pod in the <code>lab-security-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl exec --namespace lab-security -it vault-0 -- /bin/sh\n/ $\n</code></pre> <p>Your system prompt is replaced with a new prompt <code>/ $</code>. Commands issued at this prompt are executed on the <code>vault-0</code> container.</p> </li> <li> <p>Create a Kubernetes authentication role named <code>offsite-app</code>.</p> <pre><code>$ export INITIALS=ns # CHANGEME\n$ vault write auth/kubernetes/role/offsite-app-${INITIALS} \\\n    bound_service_account_names=internal-app-${INITIALS} \\\n    bound_service_account_namespaces=lab-security-offsite-${INITIALS} \\\n    policies=internal-app-${INITIALS} \\\n    ttl=24h\n</code></pre> <p>Successful output from the command resembles this example:</p> <pre><code>Success! Data written to: auth/kubernetes/role/offsite-app\n</code></pre> </li> <li> <p>Exit the <code>vault-0</code> pod.</p> </li> <li> <p>Display the deployment patch <code>patch-issues.yaml</code>.</p> <pre><code>spec:\ntemplate:\n    metadata:\n        annotations:\n        vault.hashicorp.com/agent-inject: 'true'\n        vault.hashicorp.com/agent-inject-status: 'update'\n        vault.hashicorp.com/role: 'offsite-app'\n        vault.hashicorp.com/agent-inject-secret-database-config.txt: 'internal/data/database/config'\n        vault.hashicorp.com/agent-inject-template-database-config.txt: |\n            {{- with secret \"internal/data/database/config\" -}}\n            postgresql://{{ .Data.data.username }}:{{ .Data.data.password }}@postgres:5432/wizard\n            {{- end -}}\n</code></pre> <p>The patch performs an update to set the <code>vault.hashicorp.com/role</code> to the Vault Kubernetes role <code>offsite-app-${INITIALS}</code>.</p> </li> <li> <p>Patch the <code>issues</code> deployment defined in <code>patch-issues.yaml</code>.</p> <pre><code>$ kubectl patch deployment issues --patch \\\n    \"$(cat patch-issues.yaml | sed s/offsite-app/offsite-app-${INITIALS}/g | sed s#database/config#database/config-${INITIALS}#g)\"\ndeployment.apps/issues patched\n</code></pre> <p>A new <code>issues</code> pod starts alongside the existing pod. When it is ready the original terminates and removes itself from the list of active pods.</p> </li> <li> <p>Get all the pods in the <code>lab-security-offsite-${INITIALS}</code> namespace.</p> <pre><code>$ kubectl get pods\nNAME                      READY   STATUS    RESTARTS   AGE\nissues-7fd66f98f6-ffzh7   2/2     Running   0          94s\n</code></pre> <p>Wait until the re-deployed <code>issues</code> pod reports that it is <code>Running</code> and ready (<code>2/2</code>).</p> </li> <li> <p>Finally, display the secret written to the <code>issues</code> container in the <code>issues</code> pod.</p> <pre><code>$ kubectl exec \\\n    $(kubectl get pod -l app=issues -o jsonpath=\"{.items[0].metadata.name}\") \\\n    --container issues -- cat /vault/secrets/database-config.txt\n</code></pre> <p>The secrets are rendered in a PostgreSQL connection string is present on the container:</p> <pre><code>postgresql://db-readonly-user:db-secret-password@postgres:5432/wizard\n</code></pre> </li> </ol>"},{"location":"labs/security/inject-k8s-secrets-vault/#conclusion","title":"Conclusion","text":"<p>Congrats, you have completed the lab! You launched Vault and the injector service with the Vault Helm chart. Learn more about the Vault Helm chart by reading the documentation, exploring the project source code, reading the blog post announcing the \"Injecting Vault Secrets into Kubernetes Pods via a Sidecar\", or the documentation for Agent Sidecar Injector</p> <p>Then you deployed several applications to demonstrate how this new injector service retrieves and writes these secrets for the applications to use. Explore how pods can retrieve them directly via network requests or secrets mounted on ephemeral volumes.</p> <p>An alternative option to the agent is the is the Vault Secrets Operator. It is a Kubernetes operator specifically made to aid in management of Vault on Kubernetes. This is similar to the Vault Agent sidecar, but in a Kubernetes native fashion.</p> <ul> <li>Agent Sidecar Injector</li> <li>Mutating admission webhook</li> <li>Sidecar container pattern</li> <li>Vault Secrets Operator</li> <li>Integrating Hashicorp Vault in OpenShift 4</li> <li>developer.hashicorp.com</li> </ul>"},{"location":"labs/security/openshift-rbac/","title":"Guided Exercise: Define and Apply Permissions with RBAC","text":"<p>~30 min</p> <p>Define role-based access controls and apply permissions to users.</p>"},{"location":"labs/security/openshift-rbac/#outcomes","title":"Outcomes","text":"<ul> <li>Remove project creation privileges from users who are not OpenShift cluster administrators.</li> <li>Create OpenShift groups and add members to these groups.</li> <li>Create a project and assign project administration privileges to the project.</li> <li>As a project administrator, assign read and write privileges to different groups of users.</li> </ul>"},{"location":"labs/security/openshift-rbac/#instructions","title":"Instructions","text":"<ol> <li> <p>Log in to the OpenShift cluster and determine which cluster role bindings assign the <code>self-provisioner</code> cluster role.</p> <ol> <li> <p>Run the login command in your terminal, with the login provided to you (requires admin access):</p> <pre><code>export OCP_USER=team1 # CHANGEME\nexport OCP_PASSWORD=123 # CHANGEME\nexport OCP_SERVER=https://api.example.com:6443 # CHANGEME\noc login -u ${OCP_USER} -p ${OCP_PASSWORD} --server=${OCP_SERVER}\n</code></pre> </li> <li> <p>List all cluster role bindings that reference the <code>self-provisioner</code> cluster role.</p> <pre><code>oc get clusterrolebinding -o wide | grep -E 'ROLE|self-provisioner'\n</code></pre> </li> </ol> </li> <li> <p>Remove the privilege to create projects from all users who are not cluster administrators by deleting the <code>self-provisioner</code> cluster role from the <code>system:authenticated:oauth</code> virtual group.</p> <ol> <li> <p>Confirm that the <code>self-provisioners</code> cluster role binding that you found in the previous step assigns the <code>self-provisioner</code> cluster role to the <code>system:authenticated:oauth</code> group.</p> <pre><code>oc describe clusterrolebindings self-provisioners\n</code></pre> <p>Expected output: <pre><code>Name:         self-provisioners\nLabels:       &lt;none&gt;\nAnnotations:  rbac.authorization.kubernetes.io/autoupdate: true\nRole:\n  Kind:  ClusterRole\n  Name:  self-provisioner\nSubjects:\n  Kind   Name                        Namespace\n  ----   ----                        ---------\n  Group  system:authenticated:oauth\n</code></pre></p> </li> <li> <p>Remove the <code>self-provisioner</code> cluster role from the <code>system:authenticated:oauth</code> virtual group, which deletes the <code>self-provisioners</code> role binding.</p> <pre><code>oc adm policy remove-cluster-role-from-group self-provisioner system:authenticated:oauth\n</code></pre> <p>Expected output: <pre><code>Warning: Your changes may get lost whenever a master is restarted, unless you prevent reconciliation of this rolebinding using the following command:\noc annotate clusterrolebinding.rbac self-provisioners 'rbac.authorization.kubernetes.io/autoupdate=false' --overwrite\nclusterrole.rbac.authorization.k8s.io/self-provisioner removed: \"system:authenticated:oauth\"\n</code></pre></p> <p>Note</p> <p>You can safely ignore the warning about your changes being lost.</p> </li> <li> <p>Verify that the role is removed from the group. The cluster role binding <code>self-provisioners</code> should not exist.</p> <pre><code>oc describe clusterrolebindings self-provisioners\n</code></pre> <p>Expected output: <pre><code>Error from server (NotFound): clusterrolebindings.rbac.authorization.k8s.io \"self-provisioners\" not found\n</code></pre></p> </li> <li> <p>Determine whether any other cluster role bindings reference the <code>self-provisioner</code> cluster role.</p> <pre><code>oc get clusterrolebinding -o wide | grep -E 'ROLE|self-provisioner'\n</code></pre> <p>Expected output: <pre><code>NAME      ROLE      AGE      USERS      GROUPS      SERVICEACCOUNTS\n</code></pre></p> </li> <li> <p>Log in as the <code>leader-${SUFFIX}</code> user with the <code>redhat</code> password .</p> <pre><code>export SUFFIX=${OCP_USER} # e.g. team1\noc login -u leader-${SUFFIX} -p redhat\n</code></pre> <p>Expected output: <pre><code>Login successful.\n...output omitted...\n</code></pre></p> </li> <li> <p>Try to create a project. The operation should fail.</p> <pre><code>oc new-project test\n</code></pre> <p>Expected output: <pre><code>Error from server (Forbidden): You may not request a new project via this API.\n</code></pre></p> </li> </ol> </li> <li> <p>Create a project and add project administration privileges to the <code>leader-${SUFFIX}</code> user.</p> <ol> <li> <p>Log in with your admin user:</p> <pre><code>oc login -u ${OCP_USER} -p ${OCP_PASSWORD}\n</code></pre> <p>Expected output: <pre><code>Login successful.\n...output omitted...\n</code></pre></p> </li> <li> <p>Create the <code>auth-rbac-${SUFFIX}</code> project.</p> <pre><code>oc new-project auth-rbac-${SUFFIX}\n</code></pre> <p>Expected output: <pre><code>Now using project \"auth-rbac-${SUFFIX}\" on server \"https://api.ocp4.example.com:6443\".\n...output omitted...\n</code></pre></p> </li> <li> <p>Grant project administration privileges to the <code>leader-${SUFFIX}</code> user on the <code>auth-rbac-${SUFFIX}</code> project.</p> <pre><code>oc policy add-role-to-user admin leader-${SUFFIX}\n</code></pre> <p>Expected output: <pre><code>clusterrole.rbac.authorization.k8s.io/admin added: \"leader-${SUFFIX}\"\n</code></pre></p> </li> </ol> </li> <li> <p>Create the <code>dev-group-${SUFFIX}</code> and <code>qa-group-${SUFFIX}</code> groups and add their respective members.</p> <ol> <li> <p>Create a group named <code>dev-group-${SUFFIX}</code>.</p> <pre><code>oc adm groups new dev-group-${SUFFIX}\n</code></pre> <p>Expected output: <pre><code>group.user.openshift.io/dev-group-${SUFFIX} created\n</code></pre></p> </li> <li> <p>Add the <code>developer-${SUFFIX}</code> user to the group that you created in the previous step.</p> <pre><code>oc adm groups add-users dev-group-${SUFFIX} developer-${SUFFIX}\n</code></pre> <p>Expected output: <pre><code>group.user.openshift.io/dev-group-${SUFFIX} added: \"developer-${SUFFIX}\"\n</code></pre></p> </li> <li> <p>Create a second group named <code>qa-group-${SUFFIX}</code>.</p> <pre><code>oc adm groups new qa-group-${SUFFIX}\n</code></pre> <p>Expected output: <pre><code>group.user.openshift.io/qa-group-${SUFFIX} created\n</code></pre></p> </li> <li> <p>Add the <code>qa-engineer-${SUFFIX}</code> user to the group that you created in the previous step.</p> <pre><code>oc adm groups add-users qa-group-${SUFFIX} qa-engineer-${SUFFIX}\n</code></pre> <p>Expected output: <pre><code>group.user.openshift.io/qa-group-${SUFFIX} added: \"qa-engineer-${SUFFIX}\"\n</code></pre></p> </li> <li> <p>Review all existing OpenShift groups to verify that they have the correct members.</p> <pre><code>oc get groups\n</code></pre> </li> </ol> </li> <li> <p>As the <code>leader-${SUFFIX}</code> user, assign write privileges for <code>dev-group-${SUFFIX}</code> and read privileges for <code>qa-group-${SUFFIX}</code> to the <code>auth-rbac-${SUFFIX}</code> project.</p> <ol> <li> <p>Log in as the <code>leader-${SUFFIX}</code> user.</p> <pre><code>oc login -u leader-${SUFFIX} -p redhat\n</code></pre> <p>Expected output: <pre><code>Login successful.\n\n...output omitted...\n\nUsing project \"auth-rbac-${SUFFIX}\".\n</code></pre></p> </li> <li> <p>Add write privileges to the <code>dev-group-${SUFFIX}</code> group on the <code>auth-rbac-${SUFFIX}</code> project.</p> <pre><code>oc policy add-role-to-group edit dev-group-${SUFFIX}\n</code></pre> <p>Expected output: <pre><code>clusterrole.rbac.authorization.k8s.io/edit added: \"dev-group-${SUFFIX}\"\n</code></pre></p> </li> <li> <p>Add read privileges to the <code>qa-group-${SUFFIX}</code> group on the <code>auth-rbac-${SUFFIX}</code> project.</p> <pre><code>oc policy add-role-to-group view qa-group-${SUFFIX}\n</code></pre> <p>Expected output: <pre><code>clusterrole.rbac.authorization.k8s.io/view added: \"qa-group-${SUFFIX}\"\n</code></pre></p> </li> <li> <p>Review all role bindings on the <code>auth-rbac-${SUFFIX}</code> project to verify that they assign roles to the correct groups and users. The following output omits default role bindings that OpenShift assigns to service accounts.</p> <pre><code>oc get rolebindings -o wide | grep -v '^system:'\n</code></pre> </li> </ol> </li> <li> <p>As the <code>developer-${SUFFIX}</code> user, deploy an Apache HTTP Server to prove that the <code>developer-${SUFFIX}</code> user has write privileges in the project. Also try to grant write privileges to the <code>qa-engineer-${SUFFIX}</code> user to prove that the <code>developer-${SUFFIX}</code> user has no project administration privileges.</p> <ol> <li> <p>Log in as the <code>developer-${SUFFIX}</code> user.</p> <pre><code>oc login -u developer-${SUFFIX} -p redhat\n</code></pre> <p>Expected output: <pre><code>Login successful.\n\n...output omitted...\n\nUsing project \"auth-rbac-${SUFFIX}\".\n</code></pre></p> </li> <li> <p>Deploy an Apache HTTP Server by using the standard image stream from OpenShift.</p> <pre><code>oc new-app --name httpd httpd:2.4\n</code></pre> <p>Expected output: <pre><code>_...output omitted..._\n--&gt; Creating resources ...\n    imagestreamtag.image.openshift.io \"httpd:2.4\" created\nWarning: would violate PodSecurity \"restricted:v1.24\": _...output omitted..._\n    deployment.apps \"httpd\" created\n    service \"httpd\" created\n--&gt; Success\n_...output omitted..._\n</code></pre></p> <p>Note</p> <p>It is safe to ignore pod security warnings for exercises in this course. OpenShift uses the Security Context Constraints controller to provide safe defaults for pod security.</p> </li> <li> <p>Try to grant write privileges to the <code>qa-engineer-${SUFFIX}</code> user. The operation should fail.</p> <pre><code>oc policy add-role-to-user edit qa-engineer-${SUFFIX}\n</code></pre> <p>Expected output: <pre><code>Error from server (Forbidden): rolebindings.rbac.authorization.k8s.io is forbidden: User \"developer-${SUFFIX}\" cannot list resource \"rolebindings\" in API group \"rbac.authorization.k8s.io\" in the namespace \"auth-rbac-${SUFFIX}\"\n</code></pre></p> </li> </ol> </li> <li> <p>Verify that the <code>qa-engineer-${SUFFIX}</code> user can view objects in the <code>auth-rbac-${SUFFIX}</code> project, but not modify anything.</p> <ol> <li> <p>Log in as the <code>qa-engineer-${SUFFIX}</code> user.</p> <pre><code>oc login -u qa-engineer-${SUFFIX} -p redhat\n</code></pre> <p>Expected output: <pre><code>Login successful.\n\n_...output omitted..._\n\nUsing project \"auth-rbac-${SUFFIX}\".\n</code></pre></p> </li> <li> <p>Attempt to scale the <code>httpd</code> application. The operation should fail.</p> <pre><code>oc scale deployment httpd --replicas 3\n</code></pre> <p>Expected output: <pre><code>Error from server (Forbidden): deployments.apps \"httpd\" is forbidden: User \"qa-engineer-${SUFFIX}\" cannot patch resource \"deployments/scale\" in API group \"apps\" in the namespace \"auth-rbac-${SUFFIX}\"\n</code></pre></p> </li> </ol> </li> <li> <p>Restore project creation privileges to all users.</p> <ol> <li> <p>Log in with your admin user:</p> <pre><code>oc login -u ${OCP_USER} -p ${OCP_PASSWORD}\n</code></pre> </li> <li> <p>Restore project creation privileges for all users by re-creating the <code>self-provisioners</code> cluster role binding that the OpenShift installer created.</p> <pre><code>oc adm policy add-cluster-role-to-group --rolebinding-name self-provisioners self-provisioner system:authenticated:oauth\n</code></pre> <p>Expected output: <pre><code>Warning: Group 'system:authenticated:oauth' not found\nclusterrole.rbac.authorization.k8s.io/self-provisioner added: \"system:authenticated:oauth\"\n</code></pre></p> <p>Note</p> <p>You can safely ignore the warning that the group was not found.</p> </li> </ol> </li> </ol> <p>Congrats, you have completed the lab!</p>"}]}